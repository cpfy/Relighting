{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyS1AGEUYUaG"
      },
      "source": [
        "本notebook主要实现从训练好的模型渲染rgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5alSqKnHJpw"
      },
      "source": [
        "#必做项"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbziHIDz3j9v"
      },
      "source": [
        "搭载Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0lpzDY83qLq",
        "outputId": "4b67f3bf-4bdb-4b99-b58b-c999d0e6a371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['metrics.py',\n",
              " 'README.md',\n",
              " 'LICENSE',\n",
              " 'losses.py',\n",
              " 'environment.yaml',\n",
              " 'scripts',\n",
              " 'models',\n",
              " 'evaluations',\n",
              " 'assets',\n",
              " 'rendering',\n",
              " 'opt.py',\n",
              " 'lightning_modules',\n",
              " 'datasets',\n",
              " '.gitignore',\n",
              " 'data',\n",
              " 'weights',\n",
              " 'log',\n",
              " 'config',\n",
              " 'logs',\n",
              " '__pycache__',\n",
              " 'results',\n",
              " 'requirements.txt',\n",
              " 'kaolin',\n",
              " 'checkpoints',\n",
              " 'ckpts',\n",
              " 'tools',\n",
              " 'utils',\n",
              " 'train.py',\n",
              " '\\\\']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os\n",
        "path=\"/content/drive/MyDrive/NeuralRecon-W-test\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1XEwzbSiee_"
      },
      "source": [
        "# 基础操作"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeeCv2NK3URX"
      },
      "source": [
        "##查看GPU信息"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBXp2RPa5eVL"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzO07S7y5bv9"
      },
      "source": [
        "##Restart Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6tGsadG5eRY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH1kn_rSFXEs"
      },
      "source": [
        "# 依赖包安装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n_ulxk8eCsW"
      },
      "source": [
        "注意这里装完要restart一下，不知道哪个包的原因，蛮奇怪"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NWLSOdzwFnrJ",
        "outputId": "75a8bea6-14dc-4f95-9f46-1cfcc6936558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.12.1+cu113 in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1+cu113) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting open3d==0.12.0\n",
            "  Downloading open3d-0.12.0-cp37-cp37m-manylinux2014_x86_64.whl (188.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 188.4 MB 26 kB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0) (7.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0) (1.3.5)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0) (5.3.1)\n",
            "Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0) (3.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0) (3.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0) (3.13)\n",
            "Collecting plyfile\n",
            "  Downloading plyfile-0.7.4-py3-none-any.whl (39 kB)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0) (0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from open3d==0.12.0) (4.64.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->open3d==0.12.0) (0.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->open3d==0.12.0) (5.3.4)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->open3d==0.12.0) (7.9.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->open3d==0.12.0) (1.1.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->open3d==0.12.0) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->open3d==0.12.0) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->open3d==0.12.0) (5.1.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 87.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->open3d==0.12.0) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->open3d==0.12.0) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->open3d==0.12.0) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->open3d==0.12.0) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->open3d==0.12.0) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->open3d==0.12.0) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->open3d==0.12.0) (4.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets->open3d==0.12.0) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->open3d==0.12.0) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->open3d==0.12.0) (1.15.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0) (0.13.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0) (5.4.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0) (1.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0) (2.11.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0) (4.11.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook->open3d==0.12.0) (5.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->open3d==0.12.0) (23.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->open3d==0.12.0) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->open3d==0.12.0) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->open3d==0.12.0) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->open3d==0.12.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->open3d==0.12.0) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->open3d==0.12.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->open3d==0.12.0) (4.1.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->open3d==0.12.0) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->open3d==0.12.0) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->open3d==0.12.0) (5.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->open3d==0.12.0) (0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->open3d==0.12.0) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->open3d==0.12.0) (0.6.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->open3d==0.12.0) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->open3d==0.12.0) (2.16.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->open3d==0.12.0) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->open3d==0.12.0) (5.9.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->open3d==0.12.0) (4.12.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->open3d==0.12.0) (22.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook->open3d==0.12.0) (3.8.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook->open3d==0.12.0) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->open3d==0.12.0) (2022.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->open3d==0.12.0) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->open3d==0.12.0) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->open3d==0.12.0) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->open3d==0.12.0) (1.1.0)\n",
            "Installing collected packages: jedi, plyfile, addict, open3d\n",
            "Successfully installed addict-2.4.0 jedi-0.18.1 open3d-0.12.0 plyfile-0.7.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kornia==0.4.1\n",
            "  Downloading kornia-0.4.1-py2.py3-none-any.whl (225 kB)\n",
            "\u001b[K     |████████████████████████████████| 225 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from kornia==0.4.1) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kornia==0.4.1) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->kornia==0.4.1) (4.1.1)\n",
            "Installing collected packages: kornia\n",
            "Successfully installed kornia-0.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: loguru\n",
            "Successfully installed loguru-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 582 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.12.1+cu113)\n",
            "Collecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (4.1.1)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trimesh==3.9.1\n",
            "  Downloading trimesh-3.9.1-py3-none-any.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from trimesh==3.9.1) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from trimesh==3.9.1) (57.4.0)\n",
            "Installing collected packages: trimesh\n",
            "Successfully installed trimesh-3.9.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cython==0.29.20\n",
            "  Downloading Cython-0.29.20-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 7.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: cython\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 0.29.32\n",
            "    Uninstalling Cython-0.29.32:\n",
            "      Successfully uninstalled Cython-0.29.32\n",
            "Successfully installed cython-0.29.20\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lpips==0.1.3\n",
            "  Downloading lpips-0.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: lpips\n",
            "Successfully installed lpips-0.1.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics==0.7.0\n",
            "  Downloading torchmetrics-0.7.0-py3-none-any.whl (396 kB)\n",
            "\u001b[K     |████████████████████████████████| 396 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.7.0) (1.12.1+cu113)\n",
            "Collecting pyDeprecate==0.3.*\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.7.0) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.7.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics==0.7.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics==0.7.0) (3.0.9)\n",
            "Installing collected packages: pyDeprecate, torchmetrics\n",
            "Successfully installed pyDeprecate-0.3.2 torchmetrics-0.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from yacs) (3.13)\n",
            "Installing collected packages: yacs\n",
            "Successfully installed yacs-0.1.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting test-tube==0.7.5\n",
            "  Downloading test_tube-0.7.5.tar.gz (21 kB)\n",
            "Requirement already satisfied: pandas>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from test-tube==0.7.5) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from test-tube==0.7.5) (1.21.6)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from test-tube==0.7.5) (2.9.0)\n",
            "Requirement already satisfied: tensorboard>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from test-tube==0.7.5) (2.8.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from test-tube==0.7.5) (1.12.1+cu113)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from test-tube==0.7.5) (0.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio>=2.3.0->test-tube==0.7.5) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.3->test-tube==0.7.5) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.3->test-tube==0.7.5) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.20.3->test-tube==0.7.5) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5) (1.47.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15.0->test-tube==0.7.5) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube==0.7.5) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube==0.7.5) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube==0.7.5) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15.0->test-tube==0.7.5) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.15.0->test-tube==0.7.5) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.15.0->test-tube==0.7.5) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.15.0->test-tube==0.7.5) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube==0.7.5) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->test-tube==0.7.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->test-tube==0.7.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->test-tube==0.7.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->test-tube==0.7.5) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15.0->test-tube==0.7.5) (3.2.0)\n",
            "Building wheels for collected packages: test-tube\n",
            "  Building wheel for test-tube (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for test-tube: filename=test_tube-0.7.5-py3-none-any.whl size=25356 sha256=f771bc47ab57432ef37599e2a8fef6517b8f367ed71236eba63fe9365cb544cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/50/0d/15b3236957cc18a5c39ec4d4d4d21624f4d4a876756ec17064\n",
            "Successfully built test-tube\n",
            "Installing collected packages: test-tube\n",
            "Successfully installed test-tube-0.7.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tornado==5.1.0\n",
            "  Downloading tornado-5.1.tar.gz (516 kB)\n",
            "\u001b[K     |████████████████████████████████| 516 kB 9.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: tornado\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-5.1-cp37-cp37m-linux_x86_64.whl size=462840 sha256=5d7fae8a86b496cedb9973d0133373ebb6e3b909e74238d8607850d1e2e8a1ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/53/de/6a6860ebf6d2958e20a9a8337f25b0369f1666002ade0ce284\n",
            "Successfully built tornado\n",
            "Installing collected packages: tornado\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "Successfully installed tornado-5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/cpfy/lightning@v1.4.8_origin\n",
            "  Cloning https://github.com/cpfy/lightning (to revision v1.4.8_origin) to /tmp/pip-req-build-zbz4uu06\n",
            "  Running command git clone -q https://github.com/cpfy/lightning /tmp/pip-req-build-zbz4uu06\n",
            "  Running command git checkout -b v1.4.8_origin --track origin/v1.4.8_origin\n",
            "  Switched to a new branch 'v1.4.8_origin'\n",
            "  Branch 'v1.4.8_origin' set up to track remote branch 'v1.4.8_origin' from 'origin'.\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.4.8) (1.21.6)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.4.8) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.4.8) (4.1.1)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.4.8) (2.8.0)\n",
            "Requirement already satisfied: torchmetrics>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.4.8) (0.7.0)\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 69.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.4.8) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.4.8) (4.64.0)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 94.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning==1.4.8) (3.0.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.8) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.8) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.8) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.8) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.8) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.8) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.8) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.8) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.8) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.8) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.8) (1.47.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.4.8) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.4.8) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.4.8) (4.2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.4.8) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.4.8) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.4.8) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.4.8) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.4.8) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.4.8) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (2.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.8) (1.8.1)\n",
            "Building wheels for collected packages: pytorch-lightning, future\n",
            "  Building wheel for pytorch-lightning (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-lightning: filename=pytorch_lightning-1.4.8-py3-none-any.whl size=924069 sha256=14b29b7283ffaabdc78df257acfd52cee4a3f9863172c18fa53fb26d0d132f15\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0odowkop/wheels/c3/38/30/d2cb0dfcd9946c75b7fd6a6d36178bf0a8165e4078b9493e72\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=87059ee303538c99304ed99d0a283c4e2c820e41c8af530b3f8bfff440ce3d6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built pytorch-lightning future\n",
            "Installing collected packages: pyDeprecate, fsspec, PyYAML, future, pytorch-lightning\n",
            "  Attempting uninstall: pyDeprecate\n",
            "    Found existing installation: pyDeprecate 0.3.2\n",
            "    Uninstalling pyDeprecate-0.3.2:\n",
            "      Successfully uninstalled pyDeprecate-0.3.2\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-6.0 fsspec-2022.7.1 future-0.18.2 pyDeprecate-0.3.1 pytorch-lightning-1.4.8\n",
            "env: IGNORE_TORCH_VER=1\n",
            "setup.py:37: UserWarning: Kaolin is compatible with PyTorch >=1.5.0, <=1.11.0, but found version 1.12.1+cu113. Continuing with the installed version as IGNORE_TORCH_VER is set.\n",
            "  f'Kaolin is compatible with PyTorch >={TORCH_MIN_VER}, <={TORCH_MAX_VER}, '\n",
            "Warning: passing language='c++' to cythonize() is deprecated. Instead, put \"# distutils: language=c++\" in your .pyx or .pxd file(s)\n",
            "Compiling kaolin/cython/ops/mesh/triangle_hash.pyx because it depends on /usr/local/lib/python3.7/dist-packages/Cython/Includes/libcpp/vector.pxd.\n",
            "Compiling kaolin/cython/ops/conversions/mise.pyx because it depends on /usr/local/lib/python3.7/dist-packages/Cython/Includes/libcpp/vector.pxd.\n",
            "[1/2] Cythonizing kaolin/cython/ops/conversions/mise.pyx\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/NeuralRecon-W-test/kaolin/kaolin/cython/ops/conversions/mise.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:90:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:90:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:284:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:284:33: Not all members given for struct 'Voxel'\n",
            "[2/2] Cythonizing kaolin/cython/ops/mesh/triangle_hash.pyx\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/NeuralRecon-W-test/kaolin/kaolin/cython/ops/mesh/triangle_hash.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running develop\n",
            "running egg_info\n",
            "writing kaolin.egg-info/PKG-INFO\n",
            "writing dependency_links to kaolin.egg-info/dependency_links.txt\n",
            "writing requirements to kaolin.egg-info/requires.txt\n",
            "writing top-level names to kaolin.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:411: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'kaolin.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:813: UserWarning: The detected CUDA version (11.1) has a minor version mismatch with the version that was used to compile PyTorch (11.3). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "building 'kaolin.ops.mesh.triangle_hash' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c kaolin/cython/ops/mesh/triangle_hash.cpp -o build/temp.linux-x86_64-3.7/kaolin/cython/ops/mesh/triangle_hash.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=triangle_hash -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1969:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:656\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_f_6kaolin_3ops_4mesh_13triangle_hash_12TriangleHash_query(__pyx_obj_6kaolin_3ops_4mesh_13triangle_hash_TriangleHash*, __Pyx_memviewslice, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:2880:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_6 = 0; \u001b[01;35m\u001b[K__pyx_t_6 < __pyx_t_19\u001b[m\u001b[K; __pyx_t_6+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:2889:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_6 = 0; \u001b[01;35m\u001b[K__pyx_t_6 < __pyx_t_19\u001b[m\u001b[K; __pyx_t_6+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/kaolin/cython/ops/mesh/triangle_hash.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/kaolin/ops/mesh/triangle_hash.so\n",
            "building 'kaolin.ops.conversions.mise' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c kaolin/cython/ops/conversions/mise.cpp -o build/temp.linux-x86_64-3.7/kaolin/cython/ops/conversions/mise.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=mise -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_pf_6kaolin_3ops_11conversions_4mise_4MISE_8get_points(__pyx_obj_6kaolin_3ops_11conversions_4mise_MISE*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3476:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_10 = 0; \u001b[01;35m\u001b[K__pyx_t_10 < __pyx_t_9\u001b[m\u001b[K; __pyx_t_10+=1) {\n",
            "                        \u001b[01;35m\u001b[K~~~~~~~~~~~^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid __pyx_f_6kaolin_3ops_11conversions_4mise_4MISE_subdivide_voxels(__pyx_obj_6kaolin_3ops_11conversions_4mise_MISE*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3703:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_9 = 0; \u001b[01;35m\u001b[K__pyx_t_9 < __pyx_t_11\u001b[m\u001b[K; __pyx_t_9+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3712:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     __pyx_t_12 = (((__pyx_v_self->voxels[__pyx_v_idx]).level == __pyx_v_self->depth) != 0);\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3744:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_9 = 0; \u001b[01;35m\u001b[K__pyx_t_9 < __pyx_t_11\u001b[m\u001b[K; __pyx_t_9+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3753:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     __pyx_t_12 = (((__pyx_v_self->voxels[__pyx_v_idx]).level == __pyx_v_self->depth) != 0);\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K At global scope:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:15782:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KPyObject* __pyx_convert__to_py_struct____pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D(__pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D)\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " static PyObject* \u001b[01;35m\u001b[K__pyx_convert__to_py_struct____pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D\u001b[m\u001b[K(struct __pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D s) {\n",
            "                  \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/kaolin/cython/ops/conversions/mise.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/kaolin/ops/conversions/mise.so\n",
            "copying build/lib.linux-x86_64-3.7/kaolin/_C.so -> kaolin\n",
            "copying build/lib.linux-x86_64-3.7/kaolin/ops/mesh/triangle_hash.so -> kaolin/ops/mesh\n",
            "copying build/lib.linux-x86_64-3.7/kaolin/ops/conversions/mise.so -> kaolin/ops/conversions\n",
            "Creating /usr/local/lib/python3.7/dist-packages/kaolin.egg-link (link to .)\n",
            "Adding kaolin 0.11.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/drive/MyDrive/NeuralRecon-W-test/kaolin\n",
            "Processing dependencies for kaolin==0.11.0\n",
            "Searching for usd-core<22.8\n",
            "Reading https://pypi.org/simple/usd-core/\n",
            "Downloading https://files.pythonhosted.org/packages/27/d1/e583819c4c0afb872f738d7f6eb3f8e62f817d8c1dc9945872751fa69ade/usd_core-22.5.post1-cp37-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=f7bd3aec7b8023bf17d09f740f4c81cfdcc030ba730d5e22dcbac5823361a90c\n",
            "Best match: usd-core 22.5.post1\n",
            "Processing usd_core-22.5.post1-cp37-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
            "Installing usd_core-22.5.post1-cp37-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding usd-core 22.5.post1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/usd_core-22.5.post1-py3.7-linux-x86_64.egg\n",
            "Searching for Pillow>=8.0.0\n",
            "Reading https://pypi.org/simple/Pillow/\n",
            "Downloading https://files.pythonhosted.org/packages/86/d2/ca178ad71dcd1dcddbe2a3f7983639d2f8a20e723d9a978ab978ed08c874/Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=a138441e95562b3c078746a22f8fca8ff1c22c014f856278bdbdd89ca36cff1b\n",
            "Best match: Pillow 9.2.0\n",
            "Processing Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
            "Installing Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding Pillow 9.2.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/Pillow-9.2.0-py3.7-linux-x86_64.egg\n",
            "Searching for scipy<=1.7.2,>=1.2.0\n",
            "Reading https://pypi.org/simple/scipy/\n",
            "Downloading https://files.pythonhosted.org/packages/13/2e/4843308bb8147e7f86e99d1b233c64eb4ffa70423dfe21458822cb39cb55/scipy-1.7.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl#sha256=17fd991a275e4283453f89d404209aa92059ac68d76d804b4bc1716a3742e1b5\n",
            "Best match: scipy 1.7.2\n",
            "Processing scipy-1.7.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
            "Installing scipy-1.7.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding scipy 1.7.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/scipy-1.7.2-py3.7-linux-x86_64.egg\n",
            "Searching for tqdm==4.64.0\n",
            "Best match: tqdm 4.64.0\n",
            "Adding tqdm 4.64.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for kaolin==0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.12.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install open3d==0.12.0\n",
        "!pip install kornia==0.4.1\n",
        "!pip install loguru\n",
        "!pip install torch_optimizer\n",
        "!pip install trimesh==3.9.1\n",
        "!pip install cython==0.29.20\n",
        "!pip install lpips==0.1.3\n",
        "!pip install torchmetrics==0.7.0\n",
        "!pip install yacs\n",
        "!pip install test-tube==0.7.5\n",
        "!pip install tornado==5.1.0\n",
        "#%pip install git+https://github.com/cpfy/lightning\n",
        "%pip install git+https://github.com/cpfy/lightning@v1.4.8_origin\n",
        "\n",
        "import os\n",
        "path=\"/content/drive/MyDrive/NeuralRecon-W-test/kaolin\"\n",
        "os.chdir(path)\n",
        "%env IGNORE_TORCH_VER=1\n",
        "!python setup.py develop\n",
        "path=\"/content/drive/MyDrive/NeuralRecon-W-test\"\n",
        "os.chdir(path)\n",
        "\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrOuLSOGBKmy"
      },
      "source": [
        "# 数据训练/Eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lHSTw-oKPiI"
      },
      "source": [
        "略，这里是nerf_pl nerfw的"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufQwZFoEWGcK"
      },
      "outputs": [],
      "source": [
        "!python prepare_phototourism.py --root_dir /home/ubuntu/data/IMC-PT/brandenburg_gate/ --img_downscale 8\n",
        "\n",
        "!python train.py \\\n",
        "  --root_dir /home/ubuntu/data/IMC-PT/brandenburg_gate/ --dataset_name phototourism \\\n",
        "  --img_downscale 8 --use_cache \\\n",
        "  --N_importance 64 --N_samples 64 --encode_a --encode_t --beta_min 0.03 --N_vocab 1500 --N_emb_xyz 15 \\\n",
        "  --num_epochs 20 --batch_size 1024 \\\n",
        "  --optimizer adam --lr 5e-4 --lr_scheduler cosine \\\n",
        "  --exp_name brandenburg_scale8_nerfw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXna_2xD0DcF"
      },
      "source": [
        "#Evaluating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tWjadGFWWiy"
      },
      "source": [
        "略，这里是nerf_pl nerfw的"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NQJSsaBWVS9",
        "outputId": "8999494a-ca42-4888-f957-c4f3edc8c863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 120/120 [36:33<00:00, 18.28s/it]\n"
          ]
        }
      ],
      "source": [
        "!python eval.py \\\n",
        "  --root_dir ../NeuralRecon-W-test/data/heritage-recon/brandenburg_gate \\\n",
        "  --dataset_name phototourism --scene_name brandenburg_test \\\n",
        "  --split test --N_samples 256 --N_importance 256 \\\n",
        "  --N_vocab 1500 --encode_a --encode_t \\\n",
        "  --ckpt_path ckpts/scale2_epoch.29.ckpt \\\n",
        "  --chunk 16384 --img_wh 320 240\n",
        "\n",
        "# 此处直接白嫖NeuralReconW的数据集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y07TZZCPKtp-"
      },
      "source": [
        "## 初始加载"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBf5ZQYlaffc"
      },
      "source": [
        "搭载Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd381aec-4fc9-4fe3-f5bf-c2fcb13a08f0",
        "id": "2rYE-xF4affx"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['metrics.py',\n",
              " 'README.md',\n",
              " 'LICENSE',\n",
              " 'losses.py',\n",
              " 'environment.yaml',\n",
              " 'scripts',\n",
              " 'models',\n",
              " 'evaluations',\n",
              " 'assets',\n",
              " 'rendering',\n",
              " 'opt.py',\n",
              " 'lightning_modules',\n",
              " 'datasets',\n",
              " '.gitignore',\n",
              " 'data',\n",
              " 'weights',\n",
              " 'log',\n",
              " 'config',\n",
              " 'logs',\n",
              " '__pycache__',\n",
              " 'results',\n",
              " 'requirements.txt',\n",
              " 'kaolin',\n",
              " 'checkpoints',\n",
              " 'ckpts',\n",
              " 'tools',\n",
              " 'utils',\n",
              " 'train.py',\n",
              " '\\\\']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os\n",
        "path=\"/content/drive/MyDrive/NeuralRecon-W-test\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oLGwzrsa0PD"
      },
      "source": [
        "此后章节为 `ipynb` 格式的效果复现"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#超参数\n",
        "useGPU = True #是否使用GPU\n",
        "force = True  #强制模式，除了color全扔了\n",
        "myimg_downscale = 100"
      ],
      "metadata": {
        "id": "b2wsMfQqivFx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ww2xwNSgKuuo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from utils import load_ckpt, visualize_depth  # 与nerf_pl基本一样的，参数略有变化\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# from rendering.renderer import *  在后面重新import了\n",
        "from models.nerf import *\n",
        "from models.neuconw import *  #新增neuconw模型\n",
        "\n",
        "import metrics\n",
        "\n",
        "from datasets import dataset_dict\n",
        "\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVDxu2zfKcF8"
      },
      "source": [
        "此处把eval中的dataset等参数都加载到ipynb中来（此步较慢，一般近2min）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY6Qzme6KBBr",
        "outputId": "d4b57a1d-ea1c-44c8-e72a-706bc14cf3cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading sfm result from ../neuralsfm...\n",
            "Reading images.bin..\n",
            "Reading cameras.bin..\n",
            "Compute c2w poses..\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset_dict['phototourism'] \\\n",
        "          ('data/heritage-recon/brandenburg_gate/',\n",
        "           split='test_train',\n",
        "           img_downscale=myimg_downscale, use_cache=False)\n",
        "\n",
        "#使用了与BG训练一致的img_downscale=5参数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG74CGh4Iia6"
      },
      "source": [
        "搬运defaults.py中的模型各个Net参数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IapkUHniImYI"
      },
      "outputs": [],
      "source": [
        "# from matplotlib.colors import BoundaryNorm\n",
        "from yacs.config import CfgNode as CN\n",
        "\n",
        "# defaults.py文件均用于全部参数配置\n",
        "# CN容器装载参数，管理配置，也可读写yaml用\n",
        "_CN = CN()\n",
        "\n",
        "##############  ↓  NEUS-W Pipeline  ↓  ##############\n",
        "_CN.NEUCONW = CN()\n",
        "_CN.NEUCONW.N_SAMPLES = 128   # defaults:512。尝试nerfw的128\n",
        "_CN.NEUCONW.N_IMPORTANCE = 128\n",
        "_CN.NEUCONW.USE_DISP = False\n",
        "_CN.NEUCONW.PERTURB = 1.0\n",
        "_CN.NEUCONW.NOISE_STD = 1.0\n",
        "\n",
        "# 关于 Rendering, Sample 参数\n",
        "_CN.NEUCONW.S_VAL_BASE = 0\n",
        "_CN.NEUCONW.BOUNDARY_SAMPLES = 0\n",
        "_CN.NEUCONW.NEAR_FAR_OVERRIDE = False\n",
        "_CN.NEUCONW.VOXEL_SIZE = 0.0\n",
        "_CN.NEUCONW.MIN_TRACK_LENGTH = 0\n",
        "_CN.NEUCONW.SAMPLE_RANGE = 4\n",
        "_CN.NEUCONW.SDF_THRESHOLD = 1e-3\n",
        "_CN.NEUCONW.TRAIN_VOXEL_SIZE = 0.01\n",
        "_CN.NEUCONW.UPDATE_FREQ = 2000\n",
        "\n",
        "_CN.NEUCONW.N_VOCAB = 5000  #defaults：1500\n",
        "_CN.NEUCONW.ENCODE_A = True\n",
        "_CN.NEUCONW.N_A = 48\n",
        "_CN.NEUCONW.N_A = 48\n",
        "_CN.NEUCONW.N_STATIC_HEAD = 1\n",
        "_CN.NEUCONW.ANNEAL_END = 50000\n",
        "\n",
        "_CN.NEUCONW.RENDER_BG = True\n",
        "_CN.NEUCONW.UP_SAMPLE_STEP = 4\n",
        "_CN.NEUCONW.N_OUTSIDE = 32\n",
        "_CN.NEUCONW.MESH_MASK_LIST = None\n",
        "_CN.NEUCONW.RAY_MASK_LIST = None\n",
        "_CN.NEUCONW.ENCODE_A_BG = True\n",
        "_CN.NEUCONW.FLOOR_NORMAL = False\n",
        "_CN.NEUCONW.FLOOR_LABELS = ['road']\n",
        "_CN.NEUCONW.DEPTH_LOSS = False\n",
        "\n",
        "# network config\n",
        "# 第一个SDF的Net参数：d=\\text{MLP}_{\\text{SDF}}(x)\n",
        "_CN.NEUCONW.SDF_CONFIG = CN()           # CN()容器的嵌套，外面直接调用config.NEUCONW.SDF_CONFIG\n",
        "_CN.NEUCONW.SDF_CONFIG.d_in = 3         # 输入仅为x的三维坐标xyz，因此in=3\n",
        "_CN.NEUCONW.SDF_CONFIG.d_out = 513\n",
        "_CN.NEUCONW.SDF_CONFIG.d_hidden = 512\n",
        "_CN.NEUCONW.SDF_CONFIG.n_layers = 8\n",
        "_CN.NEUCONW.SDF_CONFIG.skip_in = (4,)   # 依然保留第[4]层的skip connection\n",
        "_CN.NEUCONW.SDF_CONFIG.multires = 6\n",
        "_CN.NEUCONW.SDF_CONFIG.bias = 0.5\n",
        "_CN.NEUCONW.SDF_CONFIG.scale = 1\n",
        "_CN.NEUCONW.SDF_CONFIG.geometric_init = True\n",
        "_CN.NEUCONW.SDF_CONFIG.weight_norm = True\n",
        "_CN.NEUCONW.SDF_CONFIG.inside_outside = False\n",
        "\n",
        "# 第一个司掌Color的Net参数\n",
        "_CN.NEUCONW.COLOR_CONFIG = CN()\n",
        "_CN.NEUCONW.COLOR_CONFIG.d_in = 9\n",
        "_CN.NEUCONW.COLOR_CONFIG.d_feature = 512\n",
        "_CN.NEUCONW.COLOR_CONFIG.mode = \"idr\"\n",
        "_CN.NEUCONW.COLOR_CONFIG.d_out = 3\n",
        "_CN.NEUCONW.COLOR_CONFIG.d_hidden = 256 \n",
        "_CN.NEUCONW.COLOR_CONFIG.n_layers = 4\n",
        "_CN.NEUCONW.COLOR_CONFIG.head_channels = 128\n",
        "_CN.NEUCONW.COLOR_CONFIG.static_head_layers = 2\n",
        "_CN.NEUCONW.COLOR_CONFIG.weight_norm = True\n",
        "_CN.NEUCONW.COLOR_CONFIG.multires_view = 4\n",
        "\n",
        "_CN.NEUCONW.S_CONFIG = CN()\n",
        "_CN.NEUCONW.S_CONFIG.init_val = 0.03\n",
        "\n",
        "# loss config\n",
        "_CN.NEUCONW.LOSS = CN()\n",
        "_CN.NEUCONW.LOSS.coef = 1.0\n",
        "_CN.NEUCONW.LOSS.igr_weight = 0.1\n",
        "_CN.NEUCONW.LOSS.mask_weight = 0.1\n",
        "_CN.NEUCONW.LOSS.depth_weight = 0.1\n",
        "_CN.NEUCONW.LOSS.floor_weight = 0.01\n",
        "\n",
        "\n",
        "##############  Dataset  ##############\n",
        "_CN.DATASET = CN()\n",
        "# _CN.DATASET.ROOT_DIR = None\n",
        "_CN.DATASET.ROOT_DIR = 'data/heritage-recon/brandenburg_gate/'   # 自己eval有影响\n",
        "_CN.DATASET.DATASET_NAME = None\n",
        "_CN.DATASET.SPLIT = 'train'\n",
        "\n",
        "\n",
        "_CN.DATASET.PHOTOTOURISM = CN()\n",
        "\n",
        "# [BG]改这个参数好像对爆RAM没用？？？奇怪\n",
        "# 此处参数会被sh中也有的参数覆盖，修改无用\n",
        "_CN.DATASET.PHOTOTOURISM.IMG_DOWNSCALE = 3  # how much to downscale the images for phototourism dataset。defaults：1\n",
        "_CN.DATASET.PHOTOTOURISM.USE_CACHE = False  # whether to use ray cache (make sure img_downscale is the same)。defaults: True\n",
        "_CN.DATASET.PHOTOTOURISM.CACHE_DIR = 'cache'\n",
        "_CN.DATASET.PHOTOTOURISM.CACHE_TYPE = 'npz'\n",
        "_CN.DATASET.PHOTOTOURISM.SEMANTIC_MAP_PATH = 'semantic_maps'\n",
        "_CN.DATASET.PHOTOTOURISM.WITH_SEMANTICS = True\n",
        "\n",
        "##############  Trainer  ##############\n",
        "_CN.TRAINER = CN()\n",
        "_CN.TRAINER.WORLD_SIZE = 1\n",
        "_CN.TRAINER.CANONICAL_BS = 2048     # 标准batch size\n",
        "_CN.TRAINER.CANONICAL_LR = 1e-3     # 标准leaning rate\n",
        "_CN.TRAINER.SCALING = None          # this will be calculated automatically\n",
        "_CN.TRAINER.SAVE_DIR = 'checkpoints'\n",
        "_CN.TRAINER.VAL_FREQ = 0.125\n",
        "_CN.TRAINER.SAVE_FREQ = 5000\n",
        "\n",
        "# optimizer\n",
        "_CN.TRAINER.OPTIMIZER = \"adam\"\n",
        "_CN.TRAINER.LR = None  # this will be calculated automatically at runtime when train\n",
        "_CN.TRAINER.WEIGHT_DECAY = 0  # adam weight decay\n",
        "\n",
        "# step-based warm-up, , only applied when optimizer == 'adam'\n",
        "_CN.TRAINER.WARMUP_EPOCHS = 0\n",
        "_CN.TRAINER.WARMUP_MULTIPLIER = 1.0\n",
        "\n",
        "# learning rate scheduler\n",
        "_CN.TRAINER.LR_SCHEDULER = 'cosine'  # ['steplr', 'cosine', 'poly', 'none']\n",
        "# for steplr\n",
        "_CN.TRAINER.DECAY_STEP = []\n",
        "_CN.TRAINER.DECAY_GAMMA = 0.1\n",
        "# for poly\n",
        "_CN.TRAINER.POLY_EXP = 0.9  # exponent for polynomial learning rate decay\n",
        "\n",
        "# random seed\n",
        "_CN.TRAINER.SEED = 66\n",
        "\n",
        "config = _CN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrP7yXNohl_u"
      },
      "source": [
        "搬运 `data/heritage-recon/{$scene_name}/config.yaml` 中场景相关参数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hjC_NEUaht8N"
      },
      "outputs": [],
      "source": [
        "# 本部分为BG参数\n",
        "# yaml读取后应该自动转成json/dict格式，所以这里key都要加引号处理下，value加逗号\n",
        "\n",
        "scene_config = {\n",
        "  'name': 'brandenburg_gate',\n",
        "  'origin': [ 0.568699, -0.0935532, 6.28958 ],\n",
        "  'radius': 4.6,\n",
        "  'scale': 11.384292602539062,\n",
        "  'sfm2gt': [[-7.9858203e+00, -5.7824187e-02,  7.7921921e-01,  1.7181774e+01],\n",
        "          [-7.4605584e-01, -1.8139021e+00, -7.7805524e+00,  6.8652084e+01],\n",
        "          [ 2.3222102e-01, -7.8160243e+00,  1.7999049e+00, -1.5145728e+01],\n",
        "          [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
        "  'eval_bbx': [[-15.757790, 0.255272, -18.01238],[49.447891, 31.136766, 12.56612]],\n",
        "  'eval_bbx_detail': [[10.743, 10.879335, -2.852854],[23.1674, 13.356265, 3.828396]],\n",
        "  'voxel_size': 0.25,\n",
        "  'min_track_length': 10,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_SQCf_7MowL"
      },
      "source": [
        "初始化参数，加载模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TTMFV5KrMurv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666ebe0e-2cba-4c51-9144-3688e130d54c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(5000, 48)\n"
          ]
        }
      ],
      "source": [
        "# Change to your settings...\n",
        "############################\n",
        "\n",
        "encode_appearance = True\n",
        "ckpt_path = 'checkpoints/train-exp_BG-20220812_0039/iter_650000.ckpt'\n",
        "\n",
        "# 删去encode_transient、inchannels_t等与transient encoding相关的参数\n",
        "\n",
        "\n",
        "N_emb_xyz = 10  # 默认值15，但和ckpt不匹配\n",
        "N_emb_dir = 4\n",
        "N_samples = 128\n",
        "N_importance = 128\n",
        "use_disp = False\n",
        "\n",
        "#############################\n",
        "\n",
        "# 嵌入向量的设置\n",
        "# 实际上这里render_rays不显式传入embeddings\n",
        "# embedding_xyz = PosEmbedding(N_emb_xyz-1, N_emb_xyz)  #未使用\n",
        "# embedding_dir = PosEmbedding(N_emb_dir-1, N_emb_dir)\n",
        "# embeddings = {'xyz': embedding_xyz, 'dir': embedding_dir}\n",
        "\n",
        "embeddings={}\n",
        "\n",
        "if encode_appearance:\n",
        "    embedding_a = torch.nn.Embedding(config.NEUCONW.N_VOCAB, config.NEUCONW.N_A).cuda()\n",
        "    load_ckpt(embedding_a, ckpt_path, model_name='embedding_a')\n",
        "    embeddings['a'] = embedding_a\n",
        "    print(embedding_a)\n",
        "    \n",
        "\n",
        "# neuconW模型定义参见neuconw.py line 84，用同样方式加载出来\n",
        "\n",
        "neuconw = NeuconW(  sdfNet_config=_CN.NEUCONW.SDF_CONFIG,       # 控制符号距离函数Net，相当于NeRFW中的\\theta_1\n",
        "            colorNet_config=_CN.NEUCONW.COLOR_CONFIG,   # 控制颜色Net，相当于NeRFW中的\\theta_2\n",
        "            SNet_config=_CN.NEUCONW.S_CONFIG,           # todo 第3个Net，用于？相当于NeRFW中的\\theta_3\n",
        "            in_channels_a=48,\n",
        "            encode_a=True)\n",
        "\n",
        "# for background\n",
        "from models.nerf import NeRF\n",
        "nerf = NeRF(\n",
        "    D=8,\n",
        "    d_in=4,\n",
        "    d_in_view=3,\n",
        "    W=256,\n",
        "    multires=10,\n",
        "    multires_view=4,\n",
        "    output_ch=4,\n",
        "    skips=[4],\n",
        "    encode_appearance=config.NEUCONW.ENCODE_A_BG,      # 是否包含appearance_encoding背景？defaults.py中该值为True\n",
        "    in_channels_a=config.NEUCONW.N_A,\n",
        "    in_channels_dir=6 * config.NEUCONW.COLOR_CONFIG.multires_view + 3,\n",
        "    use_viewdirs=True,\n",
        ")\n",
        "\n",
        "if useGPU:\n",
        "  neuconw = neuconw.cuda()  # 注意这里.cuda()移动到GPU非常重要\n",
        "  nerf = nerf.cuda()\n",
        "\n",
        "# nerf_fine = NeRF('fine',\n",
        "#               in_channels_xyz=6*N_emb_xyz+3,\n",
        "#               in_channels_dir=6*N_emb_dir+3,\n",
        "#               encode_appearance=encode_appearance,\n",
        "#               in_channels_a=N_a,\n",
        "#               beta_min=beta_min).cuda()\n",
        "\n",
        "# strict表示忽略unexpected_keys或者missing_keys\n",
        "# 此处推断出来model_name='neuconw'\n",
        "load_ckpt(neuconw, ckpt_path, model_name='neuconw', strict=False)  \n",
        "load_ckpt(nerf, ckpt_path, model_name='nerf', strict=False) # nerf也得加载！不能自己新建\n",
        "\n",
        "\n",
        "# models = {'neuconw': neuconw, 'nerf': nerf}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KqkzQbEOhIP"
      },
      "source": [
        "**【废弃，仅用于参考】**批处理推断函数（in nerf_pl-nerfw）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dJVN3tr6n3wT"
      },
      "outputs": [],
      "source": [
        "# @torch.no_grad()\n",
        "# def f(rays, ts, **kwargs):\n",
        "#     \"\"\"Do batched inference on rays using chunk.\"\"\"\n",
        "#     B = rays.shape[0]\n",
        "#     results = defaultdict(list)\n",
        "#     for i in range(0, B, chunk):\n",
        "#         kwargs_ = {}\n",
        "#         if 'a_embedded' in kwargs:\n",
        "#             kwargs_['a_embedded'] = kwargs['a_embedded'][i:i+chunk]\n",
        "#         rendered_ray_chunks = \\\n",
        "#             render_rays(models,\n",
        "#                         embeddings,\n",
        "#                         rays[i:i+chunk],\n",
        "#                         ts[i:i+chunk],\n",
        "#                         N_samples,\n",
        "#                         use_disp,\n",
        "#                         0,\n",
        "#                         0,\n",
        "#                         N_importance,\n",
        "#                         chunk,\n",
        "#                         dataset.white_back,\n",
        "#                         test_time=True,\n",
        "#                         **kwargs_)\n",
        "\n",
        "#         for k, v in rendered_ray_chunks.items():\n",
        "#             results[k] += [v]\n",
        "\n",
        "#     for k, v in results.items():\n",
        "#         results[k] = torch.cat(v, 0)\n",
        "#     return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA7PLfYFfYiH"
      },
      "source": [
        "添加Renderer需要的除常量外几个参数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0MsfUJFPfbs-"
      },
      "outputs": [],
      "source": [
        "spc_options = {\n",
        "    \"voxel_size\": scene_config[\"voxel_size\"],\n",
        "    \"reconstruct_path\": config.DATASET.ROOT_DIR,\n",
        "    \"min_track_length\": scene_config[\"min_track_length\"],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22GYTQT4NQey"
      },
      "source": [
        "加入Renderer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oArf-r_NSII",
        "outputId": "872f33df-1618-4b09-d991-beab8881c594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "【Output】scene_config_path = data/heritage-recon/brandenburg_gate/config.yaml\n"
          ]
        }
      ],
      "source": [
        "if force:\n",
        "  from rendering.renderer_force import NeuconWRenderer\n",
        "else:\n",
        "  from rendering.renderer import NeuconWRenderer\n",
        "\n",
        "# config参数全手工替换一遍，显式参数版本\n",
        "# curRenderer = NeuconWRenderer(\n",
        "#     nerf=nerf,\n",
        "#     neuconw=neuconw,\n",
        "#     embeddings=embeddings,\n",
        "#     n_samples=512,\n",
        "#     s_val_base=0,\n",
        "#     n_importance=512,\n",
        "#     n_outside=32,\n",
        "#     up_sample_steps=4,\n",
        "#     perturb=1.0,\n",
        "\n",
        "#     # origin=self.scene_config[\"origin\"],\n",
        "#     # radius=self.scene_config[\"radius\"],\n",
        "#     # 这两项是data中每个场景的固定参数，在每个场景data根目录的config.yaml中\n",
        "#     origin=[ 0.568699, -0.0935532, 6.28958 ],\n",
        "#     radius=4.6,\n",
        "\n",
        "#     render_bg=True,\n",
        "#     mesh_mask_list=None,\n",
        "#     floor_normal=False,\n",
        "#     floor_labels=['road'],\n",
        "#     depth_loss=False,\n",
        "#     spc_options=spc_options,\n",
        "#     sample_range=4,\n",
        "#     boundary_samples=0,\n",
        "#     nerf_far_override=False,\n",
        "# )\n",
        "\n",
        "#另一个参数保持版本\n",
        "# renderer.py渲染器，参数基本来源于config.NEUCONW\n",
        "renderer = NeuconWRenderer(\n",
        "    nerf=nerf,\n",
        "    neuconw=neuconw,\n",
        "    embeddings=embeddings,\n",
        "    n_samples=config.NEUCONW.N_SAMPLES,\n",
        "    s_val_base=config.NEUCONW.S_VAL_BASE,\n",
        "    n_importance=config.NEUCONW.N_IMPORTANCE,\n",
        "    n_outside=config.NEUCONW.N_OUTSIDE,\n",
        "    up_sample_steps=config.NEUCONW.UP_SAMPLE_STEP,\n",
        "    perturb=1.0,\n",
        "    origin=scene_config[\"origin\"],\n",
        "    radius=scene_config[\"radius\"],\n",
        "    render_bg=config.NEUCONW.RENDER_BG,\n",
        "    mesh_mask_list=config.NEUCONW.MESH_MASK_LIST,\n",
        "    floor_normal=config.NEUCONW.FLOOR_NORMAL,\n",
        "    floor_labels=config.NEUCONW.FLOOR_LABELS,\n",
        "    depth_loss=config.NEUCONW.DEPTH_LOSS,\n",
        "    spc_options=spc_options,\n",
        "    sample_range=config.NEUCONW.SAMPLE_RANGE,\n",
        "    boundary_samples=config.NEUCONW.BOUNDARY_SAMPLES,\n",
        "    nerf_far_override=config.NEUCONW.NEAR_FAR_OVERRIDE,\n",
        "    use_gpu=useGPU,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVhGuZywLb4j"
      },
      "source": [
        "neuconw的forward函数改写"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VMe8eQEKLfbm"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "#辅助函数：cos退火\n",
        "anneal_end = config.NEUCONW.ANNEAL_END\n",
        "global_step = 10000 # 瞎写的\n",
        "def get_cos_anneal_ratio():\n",
        "    if anneal_end == 0.0:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return np.min([1.0, global_step / anneal_end])\n",
        "\n",
        "\n",
        "# 本函数基于nerf_pl中的eval.py的batched_inference改写，原函数using chunk\n",
        "# 删除，导致grad无法计算问题。但是这个可以减小GPU占用的，见：https://stackoverflow.com/questions/55322434/how-to-clear-cuda-memory-in-pytorch\n",
        "# @torch.no_grad()\n",
        "def f(rays, ts, label):\n",
        "    \"\"\"Do batched inference on rays\"\"\"\n",
        "    results = defaultdict(list)\n",
        "\n",
        "    B = rays.shape[0]\n",
        "    print(f\"B = {B}\")\n",
        "    chunk = 32\n",
        "    #尝试分chunk解决OOM\n",
        "\n",
        "    for i in range(0, B, chunk):\n",
        "      # render中仅封装了fine的结果，未使用coarse\n",
        "      rendered_ray_chunks = renderer.render(\n",
        "          # rays,\n",
        "          # ts,\n",
        "          rays[i:i+chunk],\n",
        "          ts[i:i+chunk],\n",
        "          label,\n",
        "          background_rgb=torch.zeros([1, 3], device=rays.device),\n",
        "          cos_anneal_ratio=get_cos_anneal_ratio(),\n",
        "          # cos_anneal_ratio=0.5,\n",
        "      )\n",
        "\n",
        "      for k, v in rendered_ray_chunks.items():\n",
        "          results[k] += [v]\n",
        "      \n",
        "      print(f\"【Output/f】v = {v}\")\n",
        "      \n",
        "      torch.cuda.empty_cache() \n",
        "\n",
        "    for k, v in results.items():\n",
        "        results[k] = torch.cat(v, dim=0)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJLBbm0YRXTu"
      },
      "source": [
        "## 获取单图推断结果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW-eXWgdRcI0"
      },
      "source": [
        "只需4行，十分简单。大约需要10-25s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZqgAU3pRboJ",
        "outputId": "c883fd34-e8c5-4d46-a156-f49184400604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "【Output】image path id is 62\n",
            "【Output】image name is 04800984_8342094434\n",
            "rays.shape = torch.Size([60, 8])\n",
            "ts.shape = torch.Size([60])\n",
            "ts = tensor([62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62,\n",
            "        62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62,\n",
            "        62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62,\n",
            "        62, 62, 62, 62, 62, 62])\n",
            "B = 60\n",
            "Successfully move data to device!\n",
            "【Output:renderer/876】self.embeddings = {'a': Embedding(5000, 48)}\n",
            "【Output:renderer/877】ts = tensor([62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62,\n",
            "        62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
            "       device='cuda:0')\n",
            "【Output:renderer/879】a_embedded.shape = torch.Size([32, 48])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Out]sdf device = cuda:0\n",
            "[Out]z_vals device = cuda:0\n",
            "[Out]sdf device = cuda:0\n",
            "[Out]z_vals device = cuda:0\n",
            "[Out]sdf device = cuda:0\n",
            "[Out]z_vals device = cuda:0\n",
            "[Out]sdf device = cuda:0\n",
            "[Out]z_vals device = cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "【Output/f】v = tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "【Output:renderer/876】self.embeddings = {'a': Embedding(5000, 48)}\n",
            "【Output:renderer/877】ts = tensor([62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62,\n",
            "        62, 62, 62, 62, 62, 62, 62, 62, 62, 62], device='cuda:0')\n",
            "【Output:renderer/879】a_embedded.shape = torch.Size([28, 48])\n",
            "[Out]sdf device = cuda:0\n",
            "[Out]z_vals device = cuda:0\n",
            "[Out]sdf device = cuda:0\n",
            "[Out]z_vals device = cuda:0\n",
            "[Out]sdf device = cuda:0\n",
            "[Out]z_vals device = cuda:0\n",
            "[Out]sdf device = cuda:0\n",
            "[Out]z_vals device = cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "Device of h: cuda:0\n",
            "【Output/f】v = tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# 默认参数5，实际随便取，就是图像编号id\n",
        "sample = dataset[51]\n",
        "rays = sample['rays']\n",
        "ts = sample['ts']\n",
        "\n",
        "# 同样的参数之所以这里是29256，nerfpl是182850.因为ds为2与5，原始大小除以4or25刚好差了6.25倍\n",
        "print(f\"rays.shape = {rays.shape}\")\n",
        "print(f\"ts.shape = {ts.shape}\")\n",
        "print(f\"ts = {ts}\")\n",
        "\n",
        "if useGPU:\n",
        "  rays = rays.cuda()\n",
        "  ts = ts.cuda()\n",
        "\n",
        "# 这里去除.cuda()试一下（不行，不一致）\n",
        "\n",
        "# 此方法应该是不行的，原文是lightning_modules/neuconw_system的forward函数而不是neuconw模型的\n",
        "# results = neuconw.forward(rays, ts, \"sky\")\n",
        "\n",
        "results = f(rays, ts, \"building\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLnrPxjuRl5h"
      },
      "source": [
        "绘制可视化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "QgducVN8Rnti",
        "outputId": "1d84ddcb-580e-4beb-c6d4-6c01638ab301"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-27f2f55946f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_wh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_wh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rgbs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_wh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_wh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rgb_fine'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_wh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_wh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdepth_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'depth_fine'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_wh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_wh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'view'"
          ]
        }
      ],
      "source": [
        "img_wh = tuple(sample['img_wh'].numpy())\n",
        "img_gt = sample['rgbs'].view(img_wh[1], img_wh[0], 3)\n",
        "img_pred = results['rgb_fine'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
        "depth_pred = results['depth_fine'].view(img_wh[1], img_wh[0])\n",
        "\n",
        "plt.subplots(figsize=(15, 8))\n",
        "plt.tight_layout()\n",
        "plt.subplot(231)\n",
        "plt.title('GT')\n",
        "plt.imshow(img_gt)\n",
        "plt.subplot(232)\n",
        "plt.title('pred')\n",
        "plt.imshow(img_pred)\n",
        "plt.subplot(233)\n",
        "plt.title('depth')\n",
        "plt.imshow(visualize_depth(depth_pred).permute(1,2,0))\n",
        "plt.show()\n",
        "\n",
        "print('PSNR between GT and pred:', metrics.psnr(img_gt, img_pred).item(), '\\n')\n",
        "\n",
        "\n",
        "if encode_transient:\n",
        "    print('Decomposition--------------------------------------------' + \n",
        "          '---------------------------------------------------------' +\n",
        "          '---------------------------------------------------------' + \n",
        "          '---------------------------------------------------------')\n",
        "    beta = results['beta'].view(img_wh[1], img_wh[0]).cpu().numpy()\n",
        "    img_pred_static = results['rgb_fine_static'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
        "    img_pred_transient = results['_rgb_fine_transient'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
        "    depth_pred_static = results['depth_fine_static'].view(img_wh[1], img_wh[0])\n",
        "    depth_pred_transient = results['depth_fine_transient'].view(img_wh[1], img_wh[0])\n",
        "    plt.subplots(figsize=(15, 8))\n",
        "    plt.tight_layout()\n",
        "    plt.subplot(231)\n",
        "    plt.title('static')\n",
        "    plt.imshow(img_pred_static)\n",
        "    plt.subplot(232)\n",
        "    plt.title('transient')\n",
        "    plt.imshow(img_pred_transient)\n",
        "    plt.subplot(233)\n",
        "    plt.title('uncertainty (beta)')\n",
        "    plt.imshow(beta-beta_min, cmap='gray')\n",
        "    plt.subplot(234)\n",
        "    plt.title('static depth')\n",
        "    plt.imshow(visualize_depth(depth_pred_static).permute(1,2,0))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DrAHoElS2iA"
      },
      "source": [
        "## appearance插值"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U91WWV3YS9UB"
      },
      "source": [
        "设定左右样本及插值个数，因为需要生成多个结果（约2min）\n",
        "\n",
        "使用右样本的pose，插值样本的外观编码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVCGbDQfS6hj"
      },
      "outputs": [],
      "source": [
        "left_sample = dataset[54]   # defaults:53\n",
        "right_sample = dataset[121] # defaults:111\n",
        "\n",
        "right_rays = right_sample['rays'].cuda()\n",
        "right_ts = right_sample['ts'].cuda()\n",
        "left_a_embedded = embedding_a(left_sample['ts'][0].cuda())\n",
        "right_a_embedded = embedding_a(right_sample['ts'].cuda())\n",
        "\n",
        "results_list = [left_sample]\n",
        "\n",
        "for i in range(5):\n",
        "    kwargs = {'a_embedded': right_a_embedded*i/4+left_a_embedded*(1-i/4)}\n",
        "    results_list += [f(right_rays, right_ts, **kwargs)]\n",
        "\n",
        "results_list += [right_sample]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uX2HYt5TEXG"
      },
      "source": [
        "效果绘制，说实话除了论文里的样例其它效果挺差的"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T0dt1_sTFxV"
      },
      "outputs": [],
      "source": [
        "plt.subplots(figsize=(20, 10))\n",
        "for i, results in enumerate(results_list):\n",
        "    if i == 0:\n",
        "        img_wh = tuple(results['img_wh'].numpy())\n",
        "        left_GT = results['rgbs'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
        "        plt.subplot(241)\n",
        "        plt.axis('off')\n",
        "        plt.title('left GT')\n",
        "        plt.imshow(left_GT)\n",
        "    elif i == 6:\n",
        "        img_wh = tuple(results['img_wh'].numpy())\n",
        "        right_GT = results['rgbs'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
        "        plt.subplot(247)\n",
        "        plt.axis('off')\n",
        "        plt.title('right GT')\n",
        "        plt.imshow(right_GT)\n",
        "    else:\n",
        "        img_wh = tuple(right_sample['img_wh'].numpy())\n",
        "        img_pred = results['rgb_fine'].view(img_wh[1], img_wh[0], 3).cpu().numpy()\n",
        "        plt.subplot(2, 4, i+1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(img_pred)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Y07TZZCPKtp-"
      ],
      "name": "NeuralRecon-W-rgb.ipynb",
      "toc_visible": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}