{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeRF-test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 训练相关"
      ],
      "metadata": {
        "id": "owRNtiPxBzqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "查看GPU信息"
      ],
      "metadata": {
        "id": "EVdNcSNAfW6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOFH3vQPfVw-",
        "outputId": "e0e347bb-21b4-4987-8dd8-4b89a86b0922"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul 26 03:56:40 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "挂载 Google Drive"
      ],
      "metadata": {
        "id": "I0DXC574B-KV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qomqs9_QBcL7",
        "outputId": "20a8b82c-143a-46be-a328-dce8cd7c9b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试加载环境"
      ],
      "metadata": {
        "id": "rng85n36CEcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path=\"/content/drive/MyDrive/NeRF-test\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p8kknfOB14D",
        "outputId": "9ea377b5-2cb6-4a45-d483-c059757d14fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['load_blender.py',\n",
              " 'load_deepvoxels.py',\n",
              " 'README.md',\n",
              " 'download_example_data.sh',\n",
              " 'LICENSE',\n",
              " 'requirements.txt',\n",
              " 'load_LINEMOD.py',\n",
              " '.gitignore',\n",
              " 'run_nerf_helpers.py',\n",
              " 'load_llff.py',\n",
              " '__pycache__',\n",
              " '.idea',\n",
              " 'configs',\n",
              " 'data',\n",
              " 'logs',\n",
              " 'run_nerf.py',\n",
              " 'run_nerf_250000.py',\n",
              " 'run_nerf_210000.py',\n",
              " 'run_nerf_220000.py',\n",
              " 'requirements.gdoc']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "安装依赖库（此处torch需1.11.0）"
      ],
      "metadata": {
        "id": "fghTHGCiCRqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vQPCL4fCHoE",
        "outputId": "d58f974e-4af7-410a-ed37-0ccb98e86c64"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.13.0+cu113)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (2.4.1)\n",
            "Collecting imageio-ffmpeg\n",
            "  Downloading imageio_ffmpeg-0.4.7-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Collecting configargparse\n",
            "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: tensorboard>=2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (4.64.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (4.6.0.66)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.1->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.1->-r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.1->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0->-r requirements.txt (line 7)) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0->-r requirements.txt (line 7)) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0->-r requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0->-r requirements.txt (line 7)) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0->-r requirements.txt (line 7)) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0->-r requirements.txt (line 7)) (1.47.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0->-r requirements.txt (line 7)) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0->-r requirements.txt (line 7)) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0->-r requirements.txt (line 7)) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.0->-r requirements.txt (line 7)) (4.2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.0->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.0->-r requirements.txt (line 7)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.0->-r requirements.txt (line 7)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.0->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.0->-r requirements.txt (line 7)) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.0->-r requirements.txt (line 7)) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.0->-r requirements.txt (line 7)) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.1->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.1->-r requirements.txt (line 2)) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.1->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.1->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.0->-r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n",
            "Installing collected packages: imageio-ffmpeg, configargparse\n",
            "Successfully installed configargparse-1.5.3 imageio-ffmpeg-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "仅渲染（加载目前的pretrained .tar模型）"
      ],
      "metadata": {
        "id": "VnWG2P-YCaBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_nerf.py --config configs/fern.txt --render_only"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e-zyuDQDzk8",
        "outputId": "a7a5e7c2-793f-4cca-f8c9-45dcf2561ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded image data (378, 504, 3, 20) [378.         504.         407.56579161]\n",
            "Loaded ./data/nerf_llff_data/fern 16.985296178676084 80.00209740336334\n",
            "recentered (3, 5)\n",
            "[[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  1.4901161e-09]\n",
            " [ 0.0000000e+00  1.0000000e+00 -1.8730975e-09 -9.6857544e-09]\n",
            " [-0.0000000e+00  1.8730975e-09  1.0000000e+00  0.0000000e+00]]\n",
            "Data:\n",
            "(20, 3, 5) (20, 378, 504, 3) (20, 2)\n",
            "HOLDOUT view is 12\n",
            "Loaded llff (20, 378, 504, 3) (120, 3, 5) [378.     504.     407.5658] ./data/nerf_llff_data/fern\n",
            "Auto LLFF holdout, 8\n",
            "DEFINING BOUNDS\n",
            "NEAR FAR 0.0 1.0\n",
            "Found ckpts ['./logs/fern_test/200000.tar']\n",
            "Reloading from ./logs/fern_test/200000.tar\n",
            "RENDER ONLY\n",
            "test poses shape torch.Size([120, 3, 5])\n",
            "  0% 0/120 [00:00<?, ?it/s]0 0.0013272762298583984\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "torch.Size([378, 504, 3]) torch.Size([378, 504])\n",
            "  1% 1/120 [00:22<43:47, 22.08s/it]1 22.083666801452637\n",
            "  2% 2/120 [00:40<38:55, 19.79s/it]2 18.188875675201416\n",
            "  2% 3/120 [00:58<37:24, 19.18s/it]3 18.453523874282837\n",
            "  3% 4/120 [01:17<36:45, 19.01s/it]4 18.750672578811646\n",
            "  4% 5/120 [01:36<36:24, 19.00s/it]5 18.971700191497803\n",
            "  5% 6/120 [01:55<36:08, 19.02s/it]6 19.07419729232788\n",
            "  6% 7/120 [02:14<35:58, 19.10s/it]7 19.252084493637085\n",
            "  7% 8/120 [02:34<36:10, 19.38s/it]8 19.979435443878174\n",
            "  8% 9/120 [02:55<36:29, 19.73s/it]9 20.488799810409546\n",
            "  8% 10/120 [03:15<36:22, 19.84s/it]10 20.108746767044067\n",
            "  9% 11/120 [03:35<36:03, 19.85s/it]11 19.86226201057434\n",
            " 10% 12/120 [03:55<35:46, 19.88s/it]12 19.94516396522522\n",
            " 11% 13/120 [04:15<35:34, 19.95s/it]13 20.122632265090942\n",
            " 12% 14/120 [04:35<35:20, 20.00s/it]14 20.110361576080322\n",
            " 12% 15/120 [04:55<35:00, 20.00s/it]15 20.010870695114136\n",
            " 13% 16/120 [05:15<34:39, 19.99s/it]16 19.975428342819214\n",
            " 14% 17/120 [05:35<34:18, 19.99s/it]17 19.97883152961731\n",
            " 15% 18/120 [05:55<34:00, 20.00s/it]18 20.024569988250732\n",
            " 16% 19/120 [06:15<33:40, 20.01s/it]19 20.021637439727783\n",
            " 17% 20/120 [06:35<33:20, 20.01s/it]20 20.013784408569336\n",
            " 18% 21/120 [06:55<33:00, 20.01s/it]21 20.004198789596558\n",
            " 18% 22/120 [07:15<32:41, 20.02s/it]22 20.04711079597473\n",
            " 19% 23/120 [07:35<32:22, 20.03s/it]23 20.04419493675232\n",
            " 20% 24/120 [07:55<32:03, 20.04s/it]24 20.06046199798584\n",
            " 21% 25/120 [08:15<31:44, 20.04s/it]25 20.059852600097656\n",
            " 22% 26/120 [08:35<31:24, 20.05s/it]26 20.073399543762207\n",
            " 22% 27/120 [08:55<31:05, 20.06s/it]27 20.071059942245483\n",
            " 23% 28/120 [09:15<30:45, 20.06s/it]28 20.070954084396362\n",
            " 24% 29/120 [09:35<30:27, 20.08s/it]29 20.120255708694458\n",
            " 25% 30/120 [09:56<30:06, 20.07s/it]30 20.052537441253662\n",
            " 26% 31/120 [10:16<29:45, 20.07s/it]31 20.057761192321777\n",
            " 27% 32/120 [10:36<29:24, 20.05s/it]32 20.024309635162354\n",
            " 28% 33/120 [10:56<29:03, 20.04s/it]33 20.005976676940918\n",
            " 28% 34/120 [11:16<28:42, 20.03s/it]34 20.020992755889893\n",
            " 29% 35/120 [11:36<28:23, 20.04s/it]35 20.046518325805664\n",
            " 30% 36/120 [11:56<28:04, 20.05s/it]36 20.0820369720459\n",
            " 31% 37/120 [12:16<27:44, 20.06s/it]37 20.06837296485901\n",
            " 32% 38/120 [12:36<27:25, 20.06s/it]38 20.072487115859985\n",
            " 32% 39/120 [12:56<27:05, 20.06s/it]39 20.06691074371338\n",
            " 33% 40/120 [13:16<26:45, 20.06s/it]40 20.06495690345764\n",
            " 34% 41/120 [13:36<26:25, 20.07s/it]41 20.071954011917114\n",
            " 35% 42/120 [13:56<26:04, 20.06s/it]42 20.031765937805176\n",
            " 36% 43/120 [14:16<25:43, 20.04s/it]43 20.01735258102417\n",
            " 37% 44/120 [14:36<25:21, 20.02s/it]44 19.967331409454346\n",
            " 38% 45/120 [14:56<25:00, 20.01s/it]45 19.969826459884644\n",
            " 38% 46/120 [15:16<24:39, 19.99s/it]46 19.956113576889038\n",
            " 39% 47/120 [15:36<24:18, 19.98s/it]47 19.96466088294983\n",
            " 40% 48/120 [15:56<23:59, 20.00s/it]48 20.026536464691162\n",
            " 41% 49/120 [16:16<23:40, 20.01s/it]49 20.051172494888306\n",
            " 42% 50/120 [16:36<23:21, 20.02s/it]50 20.036417722702026\n",
            " 42% 51/120 [16:56<23:03, 20.04s/it]51 20.100597381591797\n",
            " 43% 52/120 [17:16<22:44, 20.06s/it]52 20.095898628234863\n",
            " 44% 53/120 [17:36<22:24, 20.07s/it]53 20.08276343345642\n",
            " 45% 54/120 [17:56<22:04, 20.07s/it]54 20.08035135269165\n",
            " 46% 55/120 [18:17<21:45, 20.08s/it]55 20.09851622581482\n",
            " 47% 56/120 [18:37<21:24, 20.07s/it]56 20.06225085258484\n",
            " 48% 57/120 [18:57<21:04, 20.07s/it]57 20.06078863143921\n",
            " 48% 58/120 [19:17<20:43, 20.06s/it]58 20.03636407852173\n",
            " 49% 59/120 [19:37<20:23, 20.06s/it]59 20.048288345336914\n",
            " 50% 60/120 [19:57<20:03, 20.05s/it]60 20.048850774765015\n",
            " 51% 61/120 [20:17<19:43, 20.06s/it]61 20.056993007659912\n",
            " 52% 62/120 [20:37<19:24, 20.08s/it]62 20.146992444992065\n",
            " 52% 63/120 [20:57<19:05, 20.09s/it]63 20.10002112388611\n",
            " 53% 64/120 [21:17<18:45, 20.10s/it]64 20.14177703857422\n",
            " 54% 65/120 [21:37<18:26, 20.11s/it]65 20.1397066116333\n",
            " 55% 66/120 [21:58<18:06, 20.12s/it]66 20.146644592285156\n",
            " 56% 67/120 [22:18<17:46, 20.12s/it]67 20.11827826499939\n",
            " 57% 68/120 [22:38<17:26, 20.13s/it]68 20.139710903167725\n",
            " 57% 69/120 [22:58<17:05, 20.11s/it]69 20.058176517486572\n",
            " 58% 70/120 [23:18<16:44, 20.08s/it]70 20.018863439559937\n",
            " 59% 71/120 [23:38<16:23, 20.07s/it]71 20.02923345565796\n",
            " 60% 72/120 [23:58<16:02, 20.05s/it]72 20.0249981880188\n",
            " 61% 73/120 [24:18<15:42, 20.05s/it]73 20.039716720581055\n",
            " 62% 74/120 [24:38<15:22, 20.05s/it]74 20.064916133880615\n",
            " 62% 75/120 [24:58<15:03, 20.07s/it]75 20.098607063293457\n",
            " 63% 76/120 [25:18<14:42, 20.06s/it]76 20.05649209022522\n",
            " 64% 77/120 [25:38<14:22, 20.06s/it]77 20.04054856300354\n",
            " 65% 78/120 [25:58<14:02, 20.06s/it]78 20.06950092315674\n",
            " 66% 79/120 [26:18<13:42, 20.06s/it]79 20.065091133117676\n",
            " 67% 80/120 [26:38<13:22, 20.06s/it]80 20.04385995864868\n",
            " 68% 81/120 [26:58<13:02, 20.05s/it]81 20.04439401626587\n",
            " 68% 82/120 [27:19<12:42, 20.05s/it]82 20.05370807647705\n",
            " 69% 83/120 [27:39<12:21, 20.05s/it]83 20.035709857940674\n",
            " 70% 84/120 [27:59<12:01, 20.04s/it]84 20.004884958267212\n",
            " 71% 85/120 [28:19<11:41, 20.03s/it]85 20.025965929031372\n",
            " 72% 86/120 [28:39<11:21, 20.04s/it]86 20.053924560546875\n",
            " 72% 87/120 [28:59<11:01, 20.05s/it]87 20.071250438690186\n",
            " 73% 88/120 [29:19<10:41, 20.06s/it]88 20.084627151489258\n",
            " 74% 89/120 [29:39<10:22, 20.07s/it]89 20.080924034118652\n",
            " 75% 90/120 [29:59<10:01, 20.06s/it]90 20.041813373565674\n",
            " 76% 91/120 [30:19<09:41, 20.06s/it]91 20.053744316101074\n",
            " 77% 92/120 [30:39<09:21, 20.04s/it]92 20.015419244766235\n",
            " 78% 93/120 [30:59<09:00, 20.03s/it]93 20.001580476760864\n",
            " 78% 94/120 [31:19<08:40, 20.02s/it]94 20.000780820846558\n",
            " 79% 95/120 [31:39<08:20, 20.01s/it]95 19.984907627105713\n",
            " 80% 96/120 [31:59<08:00, 20.02s/it]96 20.029926538467407\n",
            " 81% 97/120 [32:19<07:40, 20.04s/it]97 20.088433027267456\n",
            " 82% 98/120 [32:39<07:21, 20.07s/it]98 20.13378119468689\n",
            " 82% 99/120 [32:59<07:01, 20.09s/it]99 20.132463216781616\n",
            " 83% 100/120 [33:19<06:41, 20.08s/it]100 20.06537127494812\n",
            " 84% 101/120 [33:39<06:21, 20.06s/it]101 20.017476320266724\n",
            " 85% 102/120 [33:59<06:00, 20.04s/it]102 19.995352745056152\n",
            " 86% 103/120 [34:19<05:40, 20.02s/it]103 19.969110250473022\n",
            " 87% 104/120 [34:39<05:20, 20.00s/it]104 19.968972206115723\n",
            " 88% 105/120 [34:59<04:59, 20.00s/it]105 19.980876922607422\n",
            " 88% 106/120 [35:19<04:39, 20.00s/it]106 20.00496768951416\n",
            " 89% 107/120 [35:39<04:20, 20.01s/it]107 20.046345710754395\n",
            " 90% 108/120 [36:00<04:00, 20.03s/it]108 20.076265335083008\n",
            " 91% 109/120 [36:20<03:40, 20.05s/it]109 20.091071844100952\n",
            " 92% 110/120 [36:40<03:20, 20.05s/it]110 20.063188552856445\n",
            " 92% 111/120 [37:00<03:00, 20.05s/it]111 20.035690784454346\n",
            " 93% 112/120 [37:20<02:40, 20.04s/it]112 20.025659322738647\n",
            " 94% 113/120 [37:40<02:20, 20.04s/it]113 20.027125358581543\n",
            " 95% 114/120 [38:00<02:00, 20.05s/it]114 20.075084447860718\n",
            " 96% 115/120 [38:20<01:40, 20.08s/it]115 20.161092281341553\n",
            " 97% 116/120 [38:40<01:20, 20.10s/it]116 20.147630214691162\n",
            " 98% 117/120 [39:00<01:00, 20.11s/it]117 20.13540244102478\n",
            " 98% 118/120 [39:20<00:40, 20.12s/it]118 20.135090589523315\n",
            " 99% 119/120 [39:41<00:20, 20.12s/it]119 20.131325721740723\n",
            "100% 120/120 [40:01<00:00, 20.01s/it]\n",
            "Done rendering ./logs/fern_test/renderonly_path_200000\n",
            "WARNING:root:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (378, 504) to (384, 512) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to None (risking incompatibility). You may also see a FFMPEG warning concerning speedloss due to data not being aligned.\n",
            "\u001b[1;34m[swscaler @ 0x5596bd7da000] \u001b[0m\u001b[0;33mWarning: data is not aligned! This can lead to a speed loss\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "默认的torch=1.12版本会有一个报错，需要1.12.1但装不了，于是回退1.11.0版本"
      ],
      "metadata": {
        "id": "KBVjDobgCkEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.11.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6K9ss-mOsUp",
        "outputId": "f7a21040-721f-4076-b597-312ffb979b38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.11.0\n",
            "  Downloading torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 750.6 MB 12 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0) (4.1.1)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.0+cu113 requires torch==1.12.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "此处尝试训练10000轮，完成后会自动在当前ckpt渲染一次\n",
        "\n",
        "换成P100之后渲染速度快一倍，从20s/iter升到10.03s/iter"
      ],
      "metadata": {
        "id": "q-nGX147IZ5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_nerf_250000.py --config configs/fern.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXehvtAOIZAZ",
        "outputId": "9de62140-acbf-4f24-a15b-60c1a2a01845"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded image data (378, 504, 3, 20) [378.         504.         407.56579161]\n",
            "Loaded ./data/nerf_llff_data/fern 16.985296178676084 80.00209740336334\n",
            "recentered (3, 5)\n",
            "[[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  1.4901161e-09]\n",
            " [ 0.0000000e+00  1.0000000e+00 -1.8730975e-09 -9.6857544e-09]\n",
            " [-0.0000000e+00  1.8730975e-09  1.0000000e+00  0.0000000e+00]]\n",
            "Data:\n",
            "(20, 3, 5) (20, 378, 504, 3) (20, 2)\n",
            "HOLDOUT view is 12\n",
            "Loaded llff (20, 378, 504, 3) (120, 3, 5) [378.     504.     407.5658] ./data/nerf_llff_data/fern\n",
            "Auto LLFF holdout, 8\n",
            "DEFINING BOUNDS\n",
            "NEAR FAR 0.0 1.0\n",
            "Found ckpts ['./logs/fern_test/200000.tar', './logs/fern_test/210000.tar', './logs/fern_test/220000.tar']\n",
            "Reloading from ./logs/fern_test/220000.tar\n",
            "get rays\n",
            "done, concats\n",
            "shuffle rays\n",
            "done\n",
            "Begin\n",
            "TRAIN views are [ 1  2  3  4  5  6  7  9 10 11 12 13 14 15 17 18 19]\n",
            "TEST views are [ 0  8 16]\n",
            "VAL views are [ 0  8 16]\n",
            "  0% 0/30001 [00:00<?, ?it/s]Saved checkpoints at ./logs/fern_test/220000.tar\n",
            "[TRAIN] Iter: 220000 Loss: 0.0036074083764106035  PSNR: 28.2404727935791\n",
            "[TRAIN] Iter: 220100 Loss: 0.0034184129908680916  PSNR: 28.535999298095703\n",
            "[TRAIN] Iter: 220200 Loss: 0.0031294224318116903  PSNR: 29.10955238342285\n",
            "[TRAIN] Iter: 220300 Loss: 0.0034345686435699463  PSNR: 28.3427734375\n",
            "[TRAIN] Iter: 220400 Loss: 0.003656685585156083  PSNR: 28.525217056274414\n",
            "[TRAIN] Iter: 220500 Loss: 0.0035102064721286297  PSNR: 28.552427291870117\n",
            "[TRAIN] Iter: 220600 Loss: 0.0037617082707583904  PSNR: 28.120256423950195\n",
            "[TRAIN] Iter: 220700 Loss: 0.003431107150390744  PSNR: 28.512807846069336\n",
            "[TRAIN] Iter: 220800 Loss: 0.003492850111797452  PSNR: 28.67656898498535\n",
            "[TRAIN] Iter: 220900 Loss: 0.0036603142507374287  PSNR: 28.613956451416016\n",
            "[TRAIN] Iter: 221000 Loss: 0.004308926872909069  PSNR: 27.71879768371582\n",
            "[TRAIN] Iter: 221100 Loss: 0.0034105987288057804  PSNR: 28.7921142578125\n",
            "[TRAIN] Iter: 221200 Loss: 0.00332952500320971  PSNR: 29.134511947631836\n",
            "[TRAIN] Iter: 221300 Loss: 0.0034191058948636055  PSNR: 28.67038345336914\n",
            "[TRAIN] Iter: 221400 Loss: 0.003273064037784934  PSNR: 28.896207809448242\n",
            "[TRAIN] Iter: 221500 Loss: 0.0032229542266577482  PSNR: 28.584218978881836\n",
            "[TRAIN] Iter: 221600 Loss: 0.003720392007380724  PSNR: 28.116512298583984\n",
            "[TRAIN] Iter: 221700 Loss: 0.003451134543865919  PSNR: 28.619579315185547\n",
            "[TRAIN] Iter: 221800 Loss: 0.0035411242861300707  PSNR: 28.74092674255371\n",
            "[TRAIN] Iter: 221900 Loss: 0.0035209087654948235  PSNR: 28.56171417236328\n",
            "[TRAIN] Iter: 222000 Loss: 0.0037427153438329697  PSNR: 28.337589263916016\n",
            "[TRAIN] Iter: 222100 Loss: 0.003258700482547283  PSNR: 29.40960121154785\n",
            "[TRAIN] Iter: 222200 Loss: 0.0031164775136858225  PSNR: 28.904197692871094\n",
            "[TRAIN] Iter: 222300 Loss: 0.0037221680395305157  PSNR: 27.824554443359375\n",
            "[TRAIN] Iter: 222400 Loss: 0.0034288247115910053  PSNR: 28.60335350036621\n",
            "[TRAIN] Iter: 222500 Loss: 0.0036695213057100773  PSNR: 28.361114501953125\n",
            "[TRAIN] Iter: 222600 Loss: 0.003591977059841156  PSNR: 28.794572830200195\n",
            "[TRAIN] Iter: 222700 Loss: 0.003281360724940896  PSNR: 29.041229248046875\n",
            "[TRAIN] Iter: 222800 Loss: 0.003686651587486267  PSNR: 28.55563735961914\n",
            "[TRAIN] Iter: 222900 Loss: 0.00386122427880764  PSNR: 27.822797775268555\n",
            "[TRAIN] Iter: 223000 Loss: 0.003215297358110547  PSNR: 28.7965087890625\n",
            "[TRAIN] Iter: 223100 Loss: 0.0030779866501688957  PSNR: 28.93472671508789\n",
            " 11% 3162/30001 [09:11<1:18:01,  5.73it/s]Shuffle data after an epoch!\n",
            "[TRAIN] Iter: 223200 Loss: 0.0033003902062773705  PSNR: 28.59855842590332\n",
            "[TRAIN] Iter: 223300 Loss: 0.0036276490427553654  PSNR: 28.531145095825195\n",
            "[TRAIN] Iter: 223400 Loss: 0.0033616716973483562  PSNR: 28.681838989257812\n",
            "[TRAIN] Iter: 223500 Loss: 0.003967061638832092  PSNR: 27.79988670349121\n",
            "[TRAIN] Iter: 223600 Loss: 0.003978032618761063  PSNR: 28.434072494506836\n",
            "[TRAIN] Iter: 223700 Loss: 0.003050214843824506  PSNR: 29.287912368774414\n",
            "[TRAIN] Iter: 223800 Loss: 0.0037343620788306  PSNR: 28.268945693969727\n",
            "[TRAIN] Iter: 223900 Loss: 0.003977975342422724  PSNR: 28.000276565551758\n",
            "[TRAIN] Iter: 224000 Loss: 0.003088954836130142  PSNR: 29.257946014404297\n",
            "[TRAIN] Iter: 224100 Loss: 0.00352771976031363  PSNR: 28.324514389038086\n",
            "[TRAIN] Iter: 224200 Loss: 0.00372488284483552  PSNR: 28.675317764282227\n",
            "[TRAIN] Iter: 224300 Loss: 0.003241523401811719  PSNR: 29.10614585876465\n",
            "[TRAIN] Iter: 224400 Loss: 0.003485393011942506  PSNR: 28.689756393432617\n",
            "[TRAIN] Iter: 224500 Loss: 0.003744826652109623  PSNR: 28.459121704101562\n",
            "[TRAIN] Iter: 224600 Loss: 0.0034241287503391504  PSNR: 28.93227195739746\n",
            "[TRAIN] Iter: 224700 Loss: 0.003664968069642782  PSNR: 28.503232955932617\n",
            "[TRAIN] Iter: 224800 Loss: 0.0032493332400918007  PSNR: 29.278980255126953\n",
            "[TRAIN] Iter: 224900 Loss: 0.003072388470172882  PSNR: 28.81986427307129\n",
            "[TRAIN] Iter: 225000 Loss: 0.003611447289586067  PSNR: 28.556259155273438\n",
            "[TRAIN] Iter: 225100 Loss: 0.003583665471524  PSNR: 28.299673080444336\n",
            "[TRAIN] Iter: 225200 Loss: 0.003137437626719475  PSNR: 28.903282165527344\n",
            "[TRAIN] Iter: 225300 Loss: 0.0038917381316423416  PSNR: 27.649206161499023\n",
            "[TRAIN] Iter: 225400 Loss: 0.003140315879136324  PSNR: 28.864234924316406\n",
            "[TRAIN] Iter: 225500 Loss: 0.0035781576298177242  PSNR: 28.788755416870117\n",
            "[TRAIN] Iter: 225600 Loss: 0.003050262574106455  PSNR: 29.24982452392578\n",
            "[TRAIN] Iter: 225700 Loss: 0.0033340416848659515  PSNR: 28.780719757080078\n",
            "[TRAIN] Iter: 225800 Loss: 0.004441217053681612  PSNR: 27.514066696166992\n",
            "[TRAIN] Iter: 225900 Loss: 0.003330353181809187  PSNR: 28.568500518798828\n",
            "[TRAIN] Iter: 226000 Loss: 0.0031644299160689116  PSNR: 28.684797286987305\n",
            "[TRAIN] Iter: 226100 Loss: 0.0031757918186485767  PSNR: 28.8851318359375\n",
            "[TRAIN] Iter: 226200 Loss: 0.003214291762560606  PSNR: 28.800033569335938\n",
            "[TRAIN] Iter: 226300 Loss: 0.003408353542909026  PSNR: 28.668262481689453\n",
            " 21% 6325/30001 [18:23<1:08:52,  5.73it/s]Shuffle data after an epoch!\n",
            "[TRAIN] Iter: 226400 Loss: 0.0034718893002718687  PSNR: 29.132143020629883\n",
            "[TRAIN] Iter: 226500 Loss: 0.003644909244030714  PSNR: 28.643455505371094\n",
            "[TRAIN] Iter: 226600 Loss: 0.003362506628036499  PSNR: 28.83873748779297\n",
            "[TRAIN] Iter: 226700 Loss: 0.002960904035717249  PSNR: 29.1498966217041\n",
            "[TRAIN] Iter: 226800 Loss: 0.004218593239784241  PSNR: 27.45958709716797\n",
            "[TRAIN] Iter: 226900 Loss: 0.0033361786045134068  PSNR: 28.699199676513672\n",
            "[TRAIN] Iter: 227000 Loss: 0.0036762054078280926  PSNR: 28.82787322998047\n",
            "[TRAIN] Iter: 227100 Loss: 0.0038958548102527857  PSNR: 28.087966918945312\n",
            "[TRAIN] Iter: 227200 Loss: 0.0036375748459249735  PSNR: 28.82398223876953\n",
            "[TRAIN] Iter: 227300 Loss: 0.0031447464134544134  PSNR: 28.791431427001953\n",
            "[TRAIN] Iter: 227400 Loss: 0.00337787251919508  PSNR: 29.156288146972656\n",
            "[TRAIN] Iter: 227500 Loss: 0.0031604089308530092  PSNR: 29.18869972229004\n",
            "[TRAIN] Iter: 227600 Loss: 0.00326477806083858  PSNR: 28.807323455810547\n",
            "[TRAIN] Iter: 227700 Loss: 0.003207656554877758  PSNR: 28.680191040039062\n",
            "[TRAIN] Iter: 227800 Loss: 0.0033214129507541656  PSNR: 28.416738510131836\n",
            "[TRAIN] Iter: 227900 Loss: 0.0036373212933540344  PSNR: 28.734235763549805\n",
            "[TRAIN] Iter: 228000 Loss: 0.003411238081753254  PSNR: 28.733646392822266\n",
            "[TRAIN] Iter: 228100 Loss: 0.003379190806299448  PSNR: 28.8203125\n",
            "[TRAIN] Iter: 228200 Loss: 0.003636061679571867  PSNR: 28.290817260742188\n",
            "[TRAIN] Iter: 228300 Loss: 0.003815458621829748  PSNR: 28.25078010559082\n",
            "[TRAIN] Iter: 228400 Loss: 0.00319491233676672  PSNR: 29.22129249572754\n",
            "[TRAIN] Iter: 228500 Loss: 0.0029916279017925262  PSNR: 29.174236297607422\n",
            "[TRAIN] Iter: 228600 Loss: 0.0038624005392193794  PSNR: 28.089080810546875\n",
            "[TRAIN] Iter: 228700 Loss: 0.003697488456964493  PSNR: 28.14482879638672\n",
            "[TRAIN] Iter: 228800 Loss: 0.003638703376054764  PSNR: 28.404624938964844\n",
            "[TRAIN] Iter: 228900 Loss: 0.00347560434602201  PSNR: 28.54345703125\n",
            "[TRAIN] Iter: 229000 Loss: 0.0034425677731633186  PSNR: 28.457719802856445\n",
            "[TRAIN] Iter: 229100 Loss: 0.00370595371350646  PSNR: 28.341144561767578\n",
            "[TRAIN] Iter: 229200 Loss: 0.002988436259329319  PSNR: 29.195415496826172\n",
            "[TRAIN] Iter: 229300 Loss: 0.00337694538757205  PSNR: 28.924020767211914\n",
            "[TRAIN] Iter: 229400 Loss: 0.0035338937304913998  PSNR: 28.712549209594727\n",
            " 32% 9488/30001 [27:35<59:28,  5.75it/s]Shuffle data after an epoch!\n",
            "[TRAIN] Iter: 229500 Loss: 0.0033014046493917704  PSNR: 28.747835159301758\n",
            "[TRAIN] Iter: 229600 Loss: 0.003777869511395693  PSNR: 27.956693649291992\n",
            "[TRAIN] Iter: 229700 Loss: 0.0035432027652859688  PSNR: 28.572704315185547\n",
            "[TRAIN] Iter: 229800 Loss: 0.0035936436615884304  PSNR: 28.513900756835938\n",
            "[TRAIN] Iter: 229900 Loss: 0.003565379884094  PSNR: 28.93608283996582\n",
            " 33% 10000/30001 [29:04<58:22,  5.71it/s]Saved checkpoints at ./logs/fern_test/230000.tar\n",
            "[TRAIN] Iter: 230000 Loss: 0.003557829186320305  PSNR: 28.760875701904297\n",
            "[TRAIN] Iter: 230100 Loss: 0.003741140943020582  PSNR: 28.403270721435547\n",
            "[TRAIN] Iter: 230200 Loss: 0.0032840901985764503  PSNR: 28.766246795654297\n",
            "[TRAIN] Iter: 230300 Loss: 0.003555496921762824  PSNR: 28.249753952026367\n",
            "[TRAIN] Iter: 230400 Loss: 0.0035587120801210403  PSNR: 28.67254638671875\n",
            "[TRAIN] Iter: 230500 Loss: 0.0038608235772699118  PSNR: 28.333505630493164\n",
            "[TRAIN] Iter: 230600 Loss: 0.003594582434743643  PSNR: 28.620824813842773\n",
            "[TRAIN] Iter: 230700 Loss: 0.003753156866878271  PSNR: 28.112369537353516\n",
            "[TRAIN] Iter: 230800 Loss: 0.0033155283890664577  PSNR: 28.632402420043945\n",
            "[TRAIN] Iter: 230900 Loss: 0.0033876439556479454  PSNR: 28.434200286865234\n",
            "[TRAIN] Iter: 231000 Loss: 0.003780404105782509  PSNR: 28.215171813964844\n",
            "[TRAIN] Iter: 231100 Loss: 0.003262764308601618  PSNR: 29.0566463470459\n",
            "[TRAIN] Iter: 231200 Loss: 0.0035343181807547808  PSNR: 28.456340789794922\n",
            "[TRAIN] Iter: 231300 Loss: 0.003615896450355649  PSNR: 28.440631866455078\n",
            "[TRAIN] Iter: 231400 Loss: 0.0033965068869292736  PSNR: 28.914764404296875\n",
            "[TRAIN] Iter: 231500 Loss: 0.0039054839871823788  PSNR: 28.053302764892578\n",
            "[TRAIN] Iter: 231600 Loss: 0.003370356047526002  PSNR: 28.825271606445312\n",
            "[TRAIN] Iter: 231700 Loss: 0.0034173589665442705  PSNR: 28.93116569519043\n",
            "[TRAIN] Iter: 231800 Loss: 0.0028557847253978252  PSNR: 29.122222900390625\n",
            "[TRAIN] Iter: 231900 Loss: 0.003516183700412512  PSNR: 28.24347496032715\n",
            "[TRAIN] Iter: 232000 Loss: 0.0029896292835474014  PSNR: 29.17935562133789\n",
            "[TRAIN] Iter: 232100 Loss: 0.0033959997817873955  PSNR: 28.713272094726562\n",
            "[TRAIN] Iter: 232200 Loss: 0.0030336373019963503  PSNR: 29.144256591796875\n",
            "[TRAIN] Iter: 232300 Loss: 0.003249726491048932  PSNR: 29.047157287597656\n",
            "[TRAIN] Iter: 232400 Loss: 0.0034369733184576035  PSNR: 28.522804260253906\n",
            "[TRAIN] Iter: 232500 Loss: 0.00397892203181982  PSNR: 28.09403419494629\n",
            "[TRAIN] Iter: 232600 Loss: 0.003909256309270859  PSNR: 27.762964248657227\n",
            " 42% 12651/30001 [36:47<50:24,  5.74it/s]Shuffle data after an epoch!\n",
            "[TRAIN] Iter: 232700 Loss: 0.0032565747387707233  PSNR: 29.2430419921875\n",
            "[TRAIN] Iter: 232800 Loss: 0.0028016003780066967  PSNR: 29.773611068725586\n",
            "[TRAIN] Iter: 232900 Loss: 0.0035377084277570248  PSNR: 28.360702514648438\n",
            "[TRAIN] Iter: 233000 Loss: 0.0035342443734407425  PSNR: 28.67336654663086\n",
            "[TRAIN] Iter: 233100 Loss: 0.0032056684140115976  PSNR: 28.939958572387695\n",
            "[TRAIN] Iter: 233200 Loss: 0.0027304007671773434  PSNR: 29.4547061920166\n",
            "[TRAIN] Iter: 233300 Loss: 0.003399366047233343  PSNR: 28.686824798583984\n",
            "[TRAIN] Iter: 233400 Loss: 0.0032793078571558  PSNR: 28.98232650756836\n",
            "[TRAIN] Iter: 233500 Loss: 0.0035132220946252346  PSNR: 28.856142044067383\n",
            "[TRAIN] Iter: 233600 Loss: 0.003077393863350153  PSNR: 28.856603622436523\n",
            "[TRAIN] Iter: 233700 Loss: 0.0036392759066075087  PSNR: 28.311304092407227\n",
            "[TRAIN] Iter: 233800 Loss: 0.003234720090404153  PSNR: 28.719356536865234\n",
            "[TRAIN] Iter: 233900 Loss: 0.0034147060941904783  PSNR: 28.397994995117188\n",
            "[TRAIN] Iter: 234000 Loss: 0.003180495463311672  PSNR: 28.854141235351562\n",
            "[TRAIN] Iter: 234100 Loss: 0.0029370044358074665  PSNR: 29.326311111450195\n",
            "[TRAIN] Iter: 234200 Loss: 0.003413988510146737  PSNR: 28.621292114257812\n",
            "[TRAIN] Iter: 234300 Loss: 0.0031844181939959526  PSNR: 29.198461532592773\n",
            "[TRAIN] Iter: 234400 Loss: 0.0035702940076589584  PSNR: 28.66724967956543\n",
            "[TRAIN] Iter: 234500 Loss: 0.0036680116318166256  PSNR: 28.27662467956543\n",
            "[TRAIN] Iter: 234600 Loss: 0.0031569511629641056  PSNR: 28.787092208862305\n",
            "[TRAIN] Iter: 234700 Loss: 0.0035997319500893354  PSNR: 28.354930877685547\n",
            "[TRAIN] Iter: 234800 Loss: 0.003361575771123171  PSNR: 28.97708511352539\n",
            "[TRAIN] Iter: 234900 Loss: 0.0034502511844038963  PSNR: 28.568572998046875\n",
            "[TRAIN] Iter: 235000 Loss: 0.0034707654267549515  PSNR: 28.566585540771484\n",
            "[TRAIN] Iter: 235100 Loss: 0.0034250514581799507  PSNR: 28.82757568359375\n",
            "[TRAIN] Iter: 235200 Loss: 0.0035337682347744703  PSNR: 28.69318389892578\n",
            "[TRAIN] Iter: 235300 Loss: 0.0036516995169222355  PSNR: 28.398067474365234\n",
            "[TRAIN] Iter: 235400 Loss: 0.0035147806629538536  PSNR: 28.582130432128906\n",
            "[TRAIN] Iter: 235500 Loss: 0.0040885405614972115  PSNR: 28.10514259338379\n",
            "[TRAIN] Iter: 235600 Loss: 0.003420512890443206  PSNR: 28.56638526916504\n",
            "[TRAIN] Iter: 235700 Loss: 0.0036107050254940987  PSNR: 28.186689376831055\n",
            "[TRAIN] Iter: 235800 Loss: 0.0033947655465453863  PSNR: 28.775712966918945\n",
            " 53% 15814/30001 [45:59<41:23,  5.71it/s]Shuffle data after an epoch!\n",
            "[TRAIN] Iter: 235900 Loss: 0.003433720674365759  PSNR: 28.846656799316406\n",
            "[TRAIN] Iter: 236000 Loss: 0.0036490983329713345  PSNR: 28.596710205078125\n",
            "[TRAIN] Iter: 236100 Loss: 0.0038422993384301662  PSNR: 28.810869216918945\n",
            "[TRAIN] Iter: 236200 Loss: 0.003694082610309124  PSNR: 28.5893611907959\n",
            "[TRAIN] Iter: 236300 Loss: 0.003536106552928686  PSNR: 28.759504318237305\n",
            "[TRAIN] Iter: 236400 Loss: 0.0033888756297528744  PSNR: 28.83784294128418\n",
            "[TRAIN] Iter: 236500 Loss: 0.0033566616475582123  PSNR: 28.78057098388672\n",
            "[TRAIN] Iter: 236600 Loss: 0.0034591658040881157  PSNR: 28.775484085083008\n",
            "[TRAIN] Iter: 236700 Loss: 0.00348271313123405  PSNR: 28.572097778320312\n",
            "[TRAIN] Iter: 236800 Loss: 0.0035106982104480267  PSNR: 28.489227294921875\n",
            "[TRAIN] Iter: 236900 Loss: 0.003403879702091217  PSNR: 28.785205841064453\n",
            "[TRAIN] Iter: 237000 Loss: 0.003104930277913809  PSNR: 29.13614845275879\n",
            "[TRAIN] Iter: 237100 Loss: 0.0038109775632619858  PSNR: 28.219728469848633\n",
            "[TRAIN] Iter: 237200 Loss: 0.0036181677132844925  PSNR: 28.45539093017578\n",
            "[TRAIN] Iter: 237300 Loss: 0.0036520175635814667  PSNR: 28.230180740356445\n",
            "[TRAIN] Iter: 237400 Loss: 0.0039713624864816666  PSNR: 28.377971649169922\n",
            "[TRAIN] Iter: 237500 Loss: 0.0035250610671937466  PSNR: 28.362060546875\n",
            "[TRAIN] Iter: 237600 Loss: 0.0035474246833473444  PSNR: 28.450105667114258\n",
            "[TRAIN] Iter: 237700 Loss: 0.00334658520296216  PSNR: 28.718008041381836\n",
            "[TRAIN] Iter: 237800 Loss: 0.0035861448850482702  PSNR: 28.52346420288086\n",
            "[TRAIN] Iter: 237900 Loss: 0.0035071675665676594  PSNR: 28.351686477661133\n",
            "[TRAIN] Iter: 238000 Loss: 0.00318709434941411  PSNR: 29.605710983276367\n",
            "[TRAIN] Iter: 238100 Loss: 0.0035970397293567657  PSNR: 28.291505813598633\n",
            "[TRAIN] Iter: 238200 Loss: 0.003416437888517976  PSNR: 28.451705932617188\n",
            "[TRAIN] Iter: 238300 Loss: 0.0038057651836425066  PSNR: 28.445337295532227\n",
            "[TRAIN] Iter: 238400 Loss: 0.0029665143229067326  PSNR: 29.03444480895996\n",
            "[TRAIN] Iter: 238500 Loss: 0.003339736256748438  PSNR: 28.71901512145996\n",
            "[TRAIN] Iter: 238600 Loss: 0.003504314925521612  PSNR: 28.75959014892578\n",
            "[TRAIN] Iter: 238700 Loss: 0.0033837147057056427  PSNR: 28.60320472717285\n",
            "[TRAIN] Iter: 238800 Loss: 0.0033519077114760876  PSNR: 28.87425422668457\n",
            "[TRAIN] Iter: 238900 Loss: 0.0044084470719099045  PSNR: 27.474605560302734\n",
            " 63% 18977/30001 [55:11<32:15,  5.70it/s]Shuffle data after an epoch!\n",
            "[TRAIN] Iter: 239000 Loss: 0.0034789200872182846  PSNR: 28.696956634521484\n",
            "[TRAIN] Iter: 239100 Loss: 0.0035488714929670095  PSNR: 28.63776397705078\n",
            "[TRAIN] Iter: 239200 Loss: 0.0037757521495223045  PSNR: 28.640546798706055\n",
            "[TRAIN] Iter: 239300 Loss: 0.003317245515063405  PSNR: 29.158842086791992\n",
            "[TRAIN] Iter: 239400 Loss: 0.0030644885264337063  PSNR: 28.973888397216797\n",
            "[TRAIN] Iter: 239500 Loss: 0.0028509986586868763  PSNR: 29.345134735107422\n",
            "[TRAIN] Iter: 239600 Loss: 0.00304837292060256  PSNR: 29.0483341217041\n",
            "[TRAIN] Iter: 239700 Loss: 0.0031012785620987415  PSNR: 29.121004104614258\n",
            "[TRAIN] Iter: 239800 Loss: 0.0035647789482027292  PSNR: 28.47479248046875\n",
            "[TRAIN] Iter: 239900 Loss: 0.0032377399038523436  PSNR: 29.17317008972168\n",
            " 67% 20000/30001 [58:10<29:08,  5.72it/s]Saved checkpoints at ./logs/fern_test/240000.tar\n",
            "[TRAIN] Iter: 240000 Loss: 0.003328789724037051  PSNR: 28.993684768676758\n",
            "[TRAIN] Iter: 240100 Loss: 0.0033062102738767862  PSNR: 28.886764526367188\n",
            "[TRAIN] Iter: 240200 Loss: 0.0030640175100415945  PSNR: 28.94761848449707\n",
            "[TRAIN] Iter: 240300 Loss: 0.003470813622698188  PSNR: 28.494922637939453\n",
            "[TRAIN] Iter: 240400 Loss: 0.00318286195397377  PSNR: 28.77718162536621\n",
            "[TRAIN] Iter: 240500 Loss: 0.003200025763362646  PSNR: 28.688295364379883\n",
            "[TRAIN] Iter: 240600 Loss: 0.00370423193089664  PSNR: 28.17867088317871\n",
            "[TRAIN] Iter: 240700 Loss: 0.003565976396203041  PSNR: 28.466785430908203\n",
            "[TRAIN] Iter: 240800 Loss: 0.0031171063892543316  PSNR: 28.977277755737305\n",
            "[TRAIN] Iter: 240900 Loss: 0.0031074564903974533  PSNR: 29.3730411529541\n",
            "[TRAIN] Iter: 241000 Loss: 0.0034622102975845337  PSNR: 28.80418586730957\n",
            "[TRAIN] Iter: 241100 Loss: 0.003965818323194981  PSNR: 27.74388885498047\n",
            "[TRAIN] Iter: 241200 Loss: 0.0039941309951245785  PSNR: 27.757801055908203\n",
            "[TRAIN] Iter: 241300 Loss: 0.003510576207190752  PSNR: 28.798851013183594\n",
            "[TRAIN] Iter: 241400 Loss: 0.003115157363936305  PSNR: 29.16290855407715\n",
            "[TRAIN] Iter: 241500 Loss: 0.0035974604543298483  PSNR: 28.5029239654541\n",
            "[TRAIN] Iter: 241600 Loss: 0.0034440779127180576  PSNR: 28.133996963500977\n",
            "[TRAIN] Iter: 241700 Loss: 0.004101819358766079  PSNR: 27.706438064575195\n",
            "[TRAIN] Iter: 241800 Loss: 0.0030297664925456047  PSNR: 29.24182891845703\n",
            "[TRAIN] Iter: 241900 Loss: 0.002935747615993023  PSNR: 29.137805938720703\n",
            "[TRAIN] Iter: 242000 Loss: 0.0034512453712522984  PSNR: 28.73977279663086\n",
            "[TRAIN] Iter: 242100 Loss: 0.003930982667952776  PSNR: 28.200572967529297\n",
            " 74% 22140/30001 [1:04:23<22:55,  5.72it/s]Shuffle data after an epoch!\n",
            "[TRAIN] Iter: 242200 Loss: 0.003392268903553486  PSNR: 28.687902450561523\n",
            "[TRAIN] Iter: 242300 Loss: 0.003059568116441369  PSNR: 29.308622360229492\n",
            "[TRAIN] Iter: 242400 Loss: 0.0029774708673357964  PSNR: 29.56904411315918\n",
            "[TRAIN] Iter: 242500 Loss: 0.003262079320847988  PSNR: 28.93140983581543\n",
            "[TRAIN] Iter: 242600 Loss: 0.0035302904434502125  PSNR: 28.543977737426758\n",
            "[TRAIN] Iter: 242700 Loss: 0.002998678246513009  PSNR: 29.157835006713867\n",
            "[TRAIN] Iter: 242800 Loss: 0.0027297537308186293  PSNR: 30.042272567749023\n",
            "[TRAIN] Iter: 242900 Loss: 0.0031868363730609417  PSNR: 28.929431915283203\n",
            "[TRAIN] Iter: 243000 Loss: 0.003770714858546853  PSNR: 28.26369285583496\n",
            "[TRAIN] Iter: 243100 Loss: 0.0032629049383103848  PSNR: 28.895248413085938\n",
            "[TRAIN] Iter: 243200 Loss: 0.0029934539925307035  PSNR: 29.44071388244629\n",
            "[TRAIN] Iter: 243300 Loss: 0.002981431782245636  PSNR: 29.30568504333496\n",
            "[TRAIN] Iter: 243400 Loss: 0.0034045432694256306  PSNR: 28.43341636657715\n",
            "[TRAIN] Iter: 243500 Loss: 0.003374454565346241  PSNR: 28.522384643554688\n",
            "[TRAIN] Iter: 243600 Loss: 0.0035352418199181557  PSNR: 28.556137084960938\n",
            "[TRAIN] Iter: 243700 Loss: 0.0034104101359844208  PSNR: 28.959047317504883\n",
            "[TRAIN] Iter: 243800 Loss: 0.0030898042023181915  PSNR: 29.494260787963867\n",
            "[TRAIN] Iter: 243900 Loss: 0.003263691905885935  PSNR: 28.981857299804688\n",
            "[TRAIN] Iter: 244000 Loss: 0.003399166278541088  PSNR: 28.53396987915039\n",
            "[TRAIN] Iter: 244100 Loss: 0.003373174462467432  PSNR: 28.305938720703125\n",
            "[TRAIN] Iter: 244200 Loss: 0.0034806649200618267  PSNR: 28.174549102783203\n",
            "[TRAIN] Iter: 244300 Loss: 0.0033528669737279415  PSNR: 28.714895248413086\n",
            "[TRAIN] Iter: 244400 Loss: 0.0039568375796079636  PSNR: 28.06761932373047\n",
            "[TRAIN] Iter: 244500 Loss: 0.00372850289568305  PSNR: 28.173465728759766\n",
            "[TRAIN] Iter: 244600 Loss: 0.0029012993909418583  PSNR: 29.637691497802734\n",
            "[TRAIN] Iter: 244700 Loss: 0.004152956418693066  PSNR: 27.740299224853516\n",
            "[TRAIN] Iter: 244800 Loss: 0.0032979180105030537  PSNR: 28.815176010131836\n",
            "[TRAIN] Iter: 244900 Loss: 0.0034051130060106516  PSNR: 28.982011795043945\n",
            "[TRAIN] Iter: 245000 Loss: 0.003756824415177107  PSNR: 28.146631240844727\n",
            "[TRAIN] Iter: 245100 Loss: 0.0033713672310113907  PSNR: 28.859018325805664\n",
            "[TRAIN] Iter: 245200 Loss: 0.0036529628559947014  PSNR: 28.390350341796875\n",
            "[TRAIN] Iter: 245300 Loss: 0.003077832981944084  PSNR: 29.079235076904297\n",
            " 84% 25303/30001 [1:13:35<13:29,  5.81it/s]Shuffle data after an epoch!\n",
            "[TRAIN] Iter: 245400 Loss: 0.003323132870718837  PSNR: 28.510906219482422\n",
            "[TRAIN] Iter: 245500 Loss: 0.0026120655238628387  PSNR: 29.830976486206055\n",
            "[TRAIN] Iter: 245600 Loss: 0.0032319810707122087  PSNR: 29.115652084350586\n",
            "[TRAIN] Iter: 245700 Loss: 0.0033494888339191675  PSNR: 28.611188888549805\n",
            "[TRAIN] Iter: 245800 Loss: 0.0034999933559447527  PSNR: 29.38985252380371\n",
            "[TRAIN] Iter: 245900 Loss: 0.00304018659517169  PSNR: 29.314098358154297\n",
            "[TRAIN] Iter: 246000 Loss: 0.003439950291067362  PSNR: 28.5577449798584\n",
            "[TRAIN] Iter: 246100 Loss: 0.0033209684770554304  PSNR: 28.749248504638672\n",
            "[TRAIN] Iter: 246200 Loss: 0.003229449037462473  PSNR: 28.968778610229492\n",
            "[TRAIN] Iter: 246300 Loss: 0.00296379835344851  PSNR: 28.99349021911621\n",
            "[TRAIN] Iter: 246400 Loss: 0.00305214268155396  PSNR: 28.95611572265625\n",
            "[TRAIN] Iter: 246500 Loss: 0.0028830901719629765  PSNR: 29.59405517578125\n",
            "[TRAIN] Iter: 246600 Loss: 0.0029302602633833885  PSNR: 28.90168571472168\n",
            "[TRAIN] Iter: 246700 Loss: 0.003335018176585436  PSNR: 28.746564865112305\n",
            "[TRAIN] Iter: 246800 Loss: 0.003148722928017378  PSNR: 29.272319793701172\n",
            "[TRAIN] Iter: 246900 Loss: 0.0026757228188216686  PSNR: 30.055774688720703\n",
            "[TRAIN] Iter: 247000 Loss: 0.003503208514302969  PSNR: 28.93375587463379\n",
            "[TRAIN] Iter: 247100 Loss: 0.0034524165093898773  PSNR: 28.768817901611328\n",
            "[TRAIN] Iter: 247200 Loss: 0.0041519952937960625  PSNR: 28.06788444519043\n",
            "[TRAIN] Iter: 247300 Loss: 0.0029023955576121807  PSNR: 29.7480411529541\n",
            "[TRAIN] Iter: 247400 Loss: 0.003819503355771303  PSNR: 28.46381187438965\n",
            "[TRAIN] Iter: 247500 Loss: 0.003122844500467181  PSNR: 29.235551834106445\n",
            "[TRAIN] Iter: 247600 Loss: 0.0032055475749075413  PSNR: 28.991531372070312\n",
            "[TRAIN] Iter: 247700 Loss: 0.003795172553509474  PSNR: 28.339221954345703\n",
            "[TRAIN] Iter: 247800 Loss: 0.003959569614380598  PSNR: 27.719491958618164\n",
            "[TRAIN] Iter: 247900 Loss: 0.0031390138901770115  PSNR: 29.029523849487305\n",
            "[TRAIN] Iter: 248000 Loss: 0.0034638824872672558  PSNR: 28.887014389038086\n",
            "[TRAIN] Iter: 248100 Loss: 0.0032327380031347275  PSNR: 28.725296020507812\n",
            "[TRAIN] Iter: 248200 Loss: 0.0033542667515575886  PSNR: 29.025875091552734\n",
            "[TRAIN] Iter: 248300 Loss: 0.003613973967730999  PSNR: 28.390268325805664\n",
            "[TRAIN] Iter: 248400 Loss: 0.0037007227074354887  PSNR: 28.096519470214844\n",
            " 95% 28466/30001 [1:22:47<04:28,  5.71it/s]Shuffle data after an epoch!\n",
            "[TRAIN] Iter: 248500 Loss: 0.0033127465285360813  PSNR: 29.189510345458984\n",
            "[TRAIN] Iter: 248600 Loss: 0.0028692190535366535  PSNR: 29.202220916748047\n",
            "[TRAIN] Iter: 248700 Loss: 0.0034222514368593693  PSNR: 28.992290496826172\n",
            "[TRAIN] Iter: 248800 Loss: 0.0035452365409582853  PSNR: 28.15062713623047\n",
            "[TRAIN] Iter: 248900 Loss: 0.004017886705696583  PSNR: 27.935443878173828\n",
            "[TRAIN] Iter: 249000 Loss: 0.003286731196567416  PSNR: 29.228078842163086\n",
            "[TRAIN] Iter: 249100 Loss: 0.0032453532330691814  PSNR: 29.04952621459961\n",
            "[TRAIN] Iter: 249200 Loss: 0.0029940514359623194  PSNR: 29.490093231201172\n",
            "[TRAIN] Iter: 249300 Loss: 0.00314519414678216  PSNR: 29.245561599731445\n",
            "[TRAIN] Iter: 249400 Loss: 0.003035172587260604  PSNR: 29.47085952758789\n",
            "[TRAIN] Iter: 249500 Loss: 0.0032648597843945026  PSNR: 28.707307815551758\n",
            "[TRAIN] Iter: 249600 Loss: 0.004279491491615772  PSNR: 27.54945945739746\n",
            "[TRAIN] Iter: 249700 Loss: 0.0032809232361614704  PSNR: 28.904041290283203\n",
            "[TRAIN] Iter: 249800 Loss: 0.003046539146453142  PSNR: 28.838884353637695\n",
            "[TRAIN] Iter: 249900 Loss: 0.0031243320554494858  PSNR: 29.030067443847656\n",
            "100% 30000/30001 [1:27:16<00:00,  5.70it/s]Saved checkpoints at ./logs/fern_test/250000.tar\n",
            "\n",
            "  0% 0/120 [00:00<?, ?it/s]\u001b[A0 0.0005919933319091797\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "torch.Size([378, 504, 3]) torch.Size([378, 504])\n",
            "\n",
            "  1% 1/120 [00:10<19:53, 10.03s/it]\u001b[A1 10.028768301010132\n",
            "\n",
            "  2% 2/120 [00:20<19:43, 10.03s/it]\u001b[A2 10.026567220687866\n",
            "\n",
            "  2% 3/120 [00:30<19:33, 10.03s/it]\u001b[A3 10.027657747268677\n",
            "\n",
            "  3% 4/120 [00:40<19:23, 10.03s/it]\u001b[A4 10.02797818183899\n",
            "\n",
            "  4% 5/120 [00:50<19:13, 10.03s/it]\u001b[A5 10.025882720947266\n",
            "\n",
            "  5% 6/120 [01:00<19:02, 10.03s/it]\u001b[A6 10.02446460723877\n",
            "\n",
            "  6% 7/120 [01:10<18:53, 10.03s/it]\u001b[A7 10.027711629867554\n",
            "\n",
            "  7% 8/120 [01:20<18:43, 10.03s/it]\u001b[A8 10.027365922927856\n",
            "\n",
            "  8% 9/120 [01:30<18:32, 10.03s/it]\u001b[A9 10.026648044586182\n",
            "\n",
            "  8% 10/120 [01:40<18:23, 10.03s/it]\u001b[A10 10.028817892074585\n",
            "\n",
            "  9% 11/120 [01:50<18:13, 10.03s/it]\u001b[A11 10.029121398925781\n",
            "\n",
            " 10% 12/120 [02:00<18:02, 10.03s/it]\u001b[A12 10.025769233703613\n",
            "\n",
            " 11% 13/120 [02:10<17:52, 10.03s/it]\u001b[A13 10.028439998626709\n",
            "\n",
            " 12% 14/120 [02:20<17:42, 10.03s/it]\u001b[A14 10.02553105354309\n",
            "\n",
            " 12% 15/120 [02:30<17:32, 10.03s/it]\u001b[A15 10.027774572372437\n",
            "\n",
            " 13% 16/120 [02:40<17:22, 10.03s/it]\u001b[A16 10.02519679069519\n",
            "\n",
            " 14% 17/120 [02:50<17:12, 10.03s/it]\u001b[A17 10.027050018310547\n",
            "\n",
            " 15% 18/120 [03:00<17:02, 10.03s/it]\u001b[A18 10.026619911193848\n",
            "\n",
            " 16% 19/120 [03:10<16:52, 10.03s/it]\u001b[A19 10.027227401733398\n",
            "\n",
            " 17% 20/120 [03:20<16:42, 10.03s/it]\u001b[A20 10.028105735778809\n",
            "\n",
            " 18% 21/120 [03:30<16:32, 10.03s/it]\u001b[A21 10.026489734649658\n",
            "\n",
            " 18% 22/120 [03:40<16:22, 10.03s/it]\u001b[A22 10.028135776519775\n",
            "\n",
            " 19% 23/120 [03:50<16:12, 10.03s/it]\u001b[A23 10.027678966522217\n",
            "\n",
            " 20% 24/120 [04:00<16:02, 10.03s/it]\u001b[A24 10.02837324142456\n",
            "\n",
            " 21% 25/120 [04:10<15:52, 10.03s/it]\u001b[A25 10.02927827835083\n",
            "\n",
            " 22% 26/120 [04:20<15:42, 10.03s/it]\u001b[A26 10.028029918670654\n",
            "\n",
            " 22% 27/120 [04:30<15:32, 10.03s/it]\u001b[A27 10.025907278060913\n",
            "\n",
            " 23% 28/120 [04:40<15:22, 10.03s/it]\u001b[A28 10.025837898254395\n",
            "\n",
            " 24% 29/120 [04:50<15:12, 10.03s/it]\u001b[A29 10.026914358139038\n",
            "\n",
            " 25% 30/120 [05:00<15:02, 10.03s/it]\u001b[A30 10.027169942855835\n",
            "\n",
            " 26% 31/120 [05:10<14:52, 10.03s/it]\u001b[A31 10.027531147003174\n",
            "\n",
            " 27% 32/120 [05:20<14:42, 10.03s/it]\u001b[A32 10.026796102523804\n",
            "\n",
            " 28% 33/120 [05:30<14:32, 10.03s/it]\u001b[A33 10.026060342788696\n",
            "\n",
            " 28% 34/120 [05:40<14:22, 10.03s/it]\u001b[A34 10.026503562927246\n",
            "\n",
            " 29% 35/120 [05:50<14:12, 10.03s/it]\u001b[A35 10.027347803115845\n",
            "\n",
            " 30% 36/120 [06:00<14:02, 10.03s/it]\u001b[A36 10.027710437774658\n",
            "\n",
            " 31% 37/120 [06:11<13:52, 10.03s/it]\u001b[A37 10.025931358337402\n",
            "\n",
            " 32% 38/120 [06:21<13:42, 10.03s/it]\u001b[A38 10.026240110397339\n",
            "\n",
            " 32% 39/120 [06:31<13:32, 10.03s/it]\u001b[A39 10.026584386825562\n",
            "\n",
            " 33% 40/120 [06:41<13:22, 10.03s/it]\u001b[A40 10.026646137237549\n",
            "\n",
            " 34% 41/120 [06:51<13:12, 10.03s/it]\u001b[A41 10.027182340621948\n",
            "\n",
            " 35% 42/120 [07:01<13:02, 10.03s/it]\u001b[A42 10.026979446411133\n",
            "\n",
            " 36% 43/120 [07:11<12:52, 10.03s/it]\u001b[A43 10.027453184127808\n",
            "\n",
            " 37% 44/120 [07:21<12:42, 10.03s/it]\u001b[A44 10.025964736938477\n",
            "\n",
            " 38% 45/120 [07:31<12:32, 10.03s/it]\u001b[A45 10.028976202011108\n",
            "\n",
            " 38% 46/120 [07:41<12:21, 10.03s/it]\u001b[A46 10.025006532669067\n",
            "\n",
            " 39% 47/120 [07:51<12:11, 10.03s/it]\u001b[A47 10.027653455734253\n",
            "\n",
            " 40% 48/120 [08:01<12:01, 10.03s/it]\u001b[A48 10.025665760040283\n",
            "\n",
            " 41% 49/120 [08:11<11:51, 10.03s/it]\u001b[A49 10.026525020599365\n",
            "\n",
            " 42% 50/120 [08:21<11:41, 10.03s/it]\u001b[A50 10.027245044708252\n",
            "\n",
            " 42% 51/120 [08:31<11:31, 10.03s/it]\u001b[A51 10.025600671768188\n",
            "\n",
            " 43% 52/120 [08:41<11:21, 10.03s/it]\u001b[A52 10.027303457260132\n",
            "\n",
            " 44% 53/120 [08:51<11:11, 10.03s/it]\u001b[A53 10.02669358253479\n",
            "\n",
            " 45% 54/120 [09:01<11:01, 10.03s/it]\u001b[A54 10.026319980621338\n",
            "\n",
            " 46% 55/120 [09:11<10:51, 10.03s/it]\u001b[A55 10.02667784690857\n",
            "\n",
            " 47% 56/120 [09:21<10:41, 10.03s/it]\u001b[A56 10.026020526885986\n",
            "\n",
            " 48% 57/120 [09:31<10:31, 10.03s/it]\u001b[A57 10.028239488601685\n",
            "\n",
            " 48% 58/120 [09:41<10:21, 10.03s/it]\u001b[A58 10.0274658203125\n",
            "\n",
            " 49% 59/120 [09:51<10:11, 10.03s/it]\u001b[A59 10.026659488677979\n",
            "\n",
            " 50% 60/120 [10:01<10:01, 10.03s/it]\u001b[A60 10.028209209442139\n",
            "\n",
            " 51% 61/120 [10:11<09:51, 10.03s/it]\u001b[A61 10.027239799499512\n",
            "\n",
            " 52% 62/120 [10:21<09:41, 10.03s/it]\u001b[A62 10.027489423751831\n",
            "\n",
            " 52% 63/120 [10:31<09:31, 10.03s/it]\u001b[A63 10.027709484100342\n",
            "\n",
            " 53% 64/120 [10:41<09:21, 10.03s/it]\u001b[A64 10.029422044754028\n",
            "\n",
            " 54% 65/120 [10:51<09:11, 10.03s/it]\u001b[A65 10.02729344367981\n",
            "\n",
            " 55% 66/120 [11:01<09:01, 10.03s/it]\u001b[A66 10.02552318572998\n",
            "\n",
            " 56% 67/120 [11:11<08:51, 10.03s/it]\u001b[A67 10.027005672454834\n",
            "\n",
            " 57% 68/120 [11:21<08:41, 10.03s/it]\u001b[A68 10.025917530059814\n",
            "\n",
            " 57% 69/120 [11:31<08:31, 10.03s/it]\u001b[A69 10.02804183959961\n",
            "\n",
            " 58% 70/120 [11:41<08:21, 10.03s/it]\u001b[A70 10.02739405632019\n",
            "\n",
            " 59% 71/120 [11:51<08:11, 10.03s/it]\u001b[A71 10.025629997253418\n",
            "\n",
            " 60% 72/120 [12:01<08:01, 10.03s/it]\u001b[A72 10.028634786605835\n",
            "\n",
            " 61% 73/120 [12:11<07:51, 10.03s/it]\u001b[A73 10.027815341949463\n",
            "\n",
            " 62% 74/120 [12:22<07:41, 10.03s/it]\u001b[A74 10.027562379837036\n",
            "\n",
            " 62% 75/120 [12:32<07:31, 10.03s/it]\u001b[A75 10.027181386947632\n",
            "\n",
            " 63% 76/120 [12:42<07:21, 10.03s/it]\u001b[A76 10.02669620513916\n",
            "\n",
            " 64% 77/120 [12:52<07:11, 10.03s/it]\u001b[A77 10.028413534164429\n",
            "\n",
            " 65% 78/120 [13:02<07:01, 10.03s/it]\u001b[A78 10.027075052261353\n",
            "\n",
            " 66% 79/120 [13:12<06:51, 10.03s/it]\u001b[A79 10.024902582168579\n",
            "\n",
            " 67% 80/120 [13:22<06:41, 10.03s/it]\u001b[A80 10.027377128601074\n",
            "\n",
            " 68% 81/120 [13:32<06:31, 10.03s/it]\u001b[A81 10.02577543258667\n",
            "\n",
            " 68% 82/120 [13:42<06:21, 10.03s/it]\u001b[A82 10.026931047439575\n",
            "\n",
            " 69% 83/120 [13:52<06:10, 10.03s/it]\u001b[A83 10.025850296020508\n",
            "\n",
            " 70% 84/120 [14:02<06:00, 10.03s/it]\u001b[A84 10.028378963470459\n",
            "\n",
            " 71% 85/120 [14:12<05:50, 10.03s/it]\u001b[A85 10.02698564529419\n",
            "\n",
            " 72% 86/120 [14:22<05:40, 10.03s/it]\u001b[A86 10.027609586715698\n",
            "\n",
            " 72% 87/120 [14:32<05:30, 10.03s/it]\u001b[A87 10.027415990829468\n",
            "\n",
            " 73% 88/120 [14:42<05:20, 10.03s/it]\u001b[A88 10.025720357894897\n",
            "\n",
            " 74% 89/120 [14:52<05:10, 10.03s/it]\u001b[A89 10.027552843093872\n",
            "\n",
            " 75% 90/120 [15:02<05:00, 10.03s/it]\u001b[A90 10.027131795883179\n",
            "\n",
            " 76% 91/120 [15:12<04:50, 10.03s/it]\u001b[A91 10.026047468185425\n",
            "\n",
            " 77% 92/120 [15:22<04:40, 10.03s/it]\u001b[A92 10.029090404510498\n",
            "\n",
            " 78% 93/120 [15:32<04:30, 10.03s/it]\u001b[A93 10.026159763336182\n",
            "\n",
            " 78% 94/120 [15:42<04:20, 10.03s/it]\u001b[A94 10.025944471359253\n",
            "\n",
            " 79% 95/120 [15:52<04:10, 10.03s/it]\u001b[A95 10.027300119400024\n",
            "\n",
            " 80% 96/120 [16:02<04:00, 10.03s/it]\u001b[A96 10.02702283859253\n",
            "\n",
            " 81% 97/120 [16:12<03:50, 10.03s/it]\u001b[A97 10.028021335601807\n",
            "\n",
            " 82% 98/120 [16:22<03:40, 10.03s/it]\u001b[A98 10.025777101516724\n",
            "\n",
            " 82% 99/120 [16:32<03:30, 10.03s/it]\u001b[A99 10.027809143066406\n",
            "\n",
            " 83% 100/120 [16:42<03:20, 10.03s/it]\u001b[A100 10.025639057159424\n",
            "\n",
            " 84% 101/120 [16:52<03:10, 10.03s/it]\u001b[A101 10.027358293533325\n",
            "\n",
            " 85% 102/120 [17:02<03:00, 10.03s/it]\u001b[A102 10.027090311050415\n",
            "\n",
            " 86% 103/120 [17:12<02:50, 10.03s/it]\u001b[A103 10.026769399642944\n",
            "\n",
            " 87% 104/120 [17:22<02:40, 10.03s/it]\u001b[A104 10.02743124961853\n",
            "\n",
            " 88% 105/120 [17:32<02:30, 10.03s/it]\u001b[A105 10.028892040252686\n",
            "\n",
            " 88% 106/120 [17:42<02:20, 10.03s/it]\u001b[A106 10.027529001235962\n",
            "\n",
            " 89% 107/120 [17:52<02:10, 10.03s/it]\u001b[A107 10.028933763504028\n",
            "\n",
            " 90% 108/120 [18:02<02:00, 10.03s/it]\u001b[A108 10.027964353561401\n",
            "\n",
            " 91% 109/120 [18:12<01:50, 10.03s/it]\u001b[A109 10.02989935874939\n",
            "\n",
            " 92% 110/120 [18:22<01:40, 10.03s/it]\u001b[A110 10.026467084884644\n",
            "\n",
            " 92% 111/120 [18:33<01:30, 10.03s/it]\u001b[A111 10.027390241622925\n",
            "\n",
            " 93% 112/120 [18:43<01:20, 10.03s/it]\u001b[A112 10.030291557312012\n",
            "\n",
            " 94% 113/120 [18:53<01:10, 10.03s/it]\u001b[A113 10.027639389038086\n",
            "\n",
            " 95% 114/120 [19:03<01:00, 10.03s/it]\u001b[A114 10.029304504394531\n",
            "\n",
            " 96% 115/120 [19:13<00:50, 10.03s/it]\u001b[A115 10.026444673538208\n",
            "\n",
            " 97% 116/120 [19:23<00:40, 10.03s/it]\u001b[A116 10.028822422027588\n",
            "\n",
            " 98% 117/120 [19:33<00:30, 10.03s/it]\u001b[A117 10.027787208557129\n",
            "\n",
            " 98% 118/120 [19:43<00:20, 10.03s/it]\u001b[A118 10.028396368026733\n",
            "\n",
            " 99% 119/120 [19:53<00:10, 10.03s/it]\u001b[A119 10.02805209159851\n",
            "\n",
            "100% 120/120 [20:03<00:00, 10.03s/it]\n",
            "Done, saving (120, 378, 504, 3) (120, 378, 504)\n",
            "WARNING:root:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (378, 504) to (384, 512) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to None (risking incompatibility). You may also see a FFMPEG warning concerning speedloss due to data not being aligned.\n",
            "\u001b[1;34m[swscaler @ 0x562a8ba10000] \u001b[0m\u001b[0;33mWarning: data is not aligned! This can lead to a speed loss\n",
            "\u001b[0mWARNING:root:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (378, 504) to (384, 512) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to None (risking incompatibility). You may also see a FFMPEG warning concerning speedloss due to data not being aligned.\n",
            "\u001b[1;34m[swscaler @ 0x555afadac000] \u001b[0m\u001b[0;33mWarning: data is not aligned! This can lead to a speed loss\n",
            "\u001b[0mtest poses shape torch.Size([3, 3, 4])\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A0 0.0005896091461181641\n",
            "torch.Size([378, 504, 3]) torch.Size([378, 504])\n",
            "\n",
            " 33% 1/3 [00:10<00:20, 10.21s/it]\u001b[A1 10.207940340042114\n",
            "\n",
            " 67% 2/3 [00:20<00:10, 10.20s/it]\u001b[A2 10.197962045669556\n",
            "\n",
            "100% 3/3 [00:30<00:00, 10.20s/it]\n",
            "Saved test set\n",
            "[TRAIN] Iter: 250000 Loss: 0.0032136072404682636  PSNR: 28.985340118408203\n",
            "100% 30001/30001 [1:47:57<00:00,  4.63it/s] \n"
          ]
        }
      ]
    }
  ]
}